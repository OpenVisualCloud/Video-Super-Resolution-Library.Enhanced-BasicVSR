From 1579868d3aafdfdbdb0c9ebb54d38f015a0dbe1c Mon Sep 17 00:00:00 2001
From: YanjiePa <yanjie.pan@intel.com>
Date: Thu, 29 Sep 2022 09:26:30 +0800
Subject: [PATCH 16/17] Vsr opt dev (#20)

* add verbose control to memmory debug message (#19)

* addressed GPU inference issue and deleted some useless annotations (#18)

* modified the index searching method for flow_warp input1

* delete useless annotations

Co-authored-by: Jiang, Renzhi <renzhi.jiang@intel.com>
Co-authored-by: KunLong9 <105702843+KunLong9@users.noreply.github.com>
---
 flow_warp_custom_op/flow_warp.cl              |  5 +-
 .../intel_gpu/src/runtime/memory_pool.cpp     | 10 ++--
 .../cross_check_tool/cross_check_tool.py      |  4 +-
 .../openvino/tools/cross_check_tool/utils.py  |  5 +-
 vsr_opt/tools/quantization.py                 | 50 +++----------------
 5 files changed, 20 insertions(+), 54 deletions(-)

diff --git a/flow_warp_custom_op/flow_warp.cl b/flow_warp_custom_op/flow_warp.cl
index f733b3a86a..fb537bac0b 100755
--- a/flow_warp_custom_op/flow_warp.cl
+++ b/flow_warp_custom_op/flow_warp.cl
@@ -27,15 +27,16 @@ __kernel void flow_warp(
     
 #if OUTPUT0_BATCH_NUM == 1
     uint f = get_global_id(2);
-    uint b = 1;
+    uint b = 0;
 #else
     uint f = get_global_id(2) % OUTPUT0_DIMS[1];
     uint b = get_global_id(2) / OUTPUT0_DIMS[1];
 #endif //OUTPUT_BATCH_NUM > 1
 
     //get flow value
-    uint ind_x = GET_DATA_INDEX(INPUT1, b , 2, y, x);
+    uint ind_x = GET_DATA_INDEX(INPUT1, b , y, x, 0);
     uint ind_y = ind_x + 1;
+
     
     // get input pixel
     INPUT1_TYPE flow_x = input1[ind_x] + x;
diff --git a/src/plugins/intel_gpu/src/runtime/memory_pool.cpp b/src/plugins/intel_gpu/src/runtime/memory_pool.cpp
index 7bd23b31ad..1196ae20ac 100644
--- a/src/plugins/intel_gpu/src/runtime/memory_pool.cpp
+++ b/src/plugins/intel_gpu/src/runtime/memory_pool.cpp
@@ -214,10 +214,12 @@ memory::ptr memory_pool::get_from_non_padded_pool(const layout& layout,
 
     //TODO: temporary workround for insufficient memory by Renzhi
     auto allocated_memory = _engine->get_used_device_memory(type);
-    if (type == allocation_type::usm_device &&
-         allocated_memory + layout.bytes_count() > _engine->get_device_info().max_global_mem_size) {
-            GPU_DEBUG_COUT << "Warning: No available device memory for " << id << ", will use system memory instead." << std::endl;
-        return nullptr;
+    GPU_DEBUG_IF(debug_config->verbose >= 1) {
+        if (type == allocation_type::usm_device &&
+            allocated_memory + layout.bytes_count() > _engine->get_device_info().max_global_mem_size) {
+                GPU_DEBUG_COUT << "Warning: No available device memory for " << id << ", will use system memory instead." << std::endl;
+            return nullptr;
+        }
     }
     // didn't find anything for you? create new resource
     auto mem = alloc_memory(layout, type);
diff --git a/tools/cross_check_tool/openvino/tools/cross_check_tool/cross_check_tool.py b/tools/cross_check_tool/openvino/tools/cross_check_tool/cross_check_tool.py
index a8aa1fc6bb..29283b1732 100755
--- a/tools/cross_check_tool/openvino/tools/cross_check_tool/cross_check_tool.py
+++ b/tools/cross_check_tool/openvino/tools/cross_check_tool/cross_check_tool.py
@@ -38,14 +38,14 @@ def set_cpu_extensions(core: Core, cpu_ext: str):
     core.add_extension(cpu_ext)
 
 
-def get_plugin(device: str, cpu_ext: str = None, config: str = None, gpu_config:str =None):  # @longkun: , gpu_config:str =None
+def get_plugin(device: str, cpu_ext: str = None, config: str = None, gpu_config:str =None):  
     core = Core()
     # log.info('{} plugin:\n          API version ............ {}'.format(device, plugin.version), extra={'no_lvl': True})
     set_plugin_config(core=core, device=device, config=config)
     if cpu_ext and 'CPU' in device:
         set_cpu_extensions(core=core, cpu_ext=cpu_ext)
     
-    # GPU config for custom op  # @longkun:
+    # GPU config for custom op  
     if cpu_ext and 'GPU' in device:
         core.add_extension(cpu_ext)
         core.set_property('GPU', {'CONFIG_FILE': gpu_config})
diff --git a/tools/cross_check_tool/openvino/tools/cross_check_tool/utils.py b/tools/cross_check_tool/openvino/tools/cross_check_tool/utils.py
index b00bdaa733..2dcc5bd3e4 100755
--- a/tools/cross_check_tool/openvino/tools/cross_check_tool/utils.py
+++ b/tools/cross_check_tool/openvino/tools/cross_check_tool/utils.py
@@ -198,7 +198,7 @@ def build_parser():
                              ' libraries with the kernels implementation.')
     plugin.add_argument('--path_to_cldnn_config', '-c', type=str, action=ExistingFileAction,
                         help='Required for GPU custom kernels. Absolute path to an .xml file with the '
-                             'kernels description.')  # @longkun:
+                             'kernels description.')  
 
     modes = parser.add_argument_group('CCT mode arguments')
     # TODO eps? nobody uses it
@@ -523,8 +523,7 @@ def print_all_over_the_net_metrics(global_accuracy: list, global_times: list = N
 def get_ops_list(all_ops: list, outputs: list, layers: str):
     if layers is not None and layers != 'None':
         if layers == 'all':
-            # return [op for op in all_ops if op.get_type_name() not in ['Constant', 'Result', 'Parameter', 'Less', 'Greater', 'Equal', 'Convolution']]
-            return [op for op in all_ops if op.get_type_name() in ['Gather']]  #@longkun:
+            return [op for op in all_ops if op.get_type_name() not in ['Constant', 'Result', 'Parameter', 'Less', 'Greater', 'Equal', 'Convolution']]
         else:
             all_ops_map = {op.friendly_name: op for op in all_ops}
             user_ops = [layer.strip() for layer in layers.split(',')]
diff --git a/vsr_opt/tools/quantization.py b/vsr_opt/tools/quantization.py
index 6df740e843..39bf716dca 100755
--- a/vsr_opt/tools/quantization.py
+++ b/vsr_opt/tools/quantization.py
@@ -13,7 +13,6 @@ from openvino.tools.pot import DataLoader
 from openvino.tools.pot import Metric
 import math
 import cv2
-# import mmcv
 import math
 
 from openvino.tools.pot.utils.logger import init_logger,get_logger
@@ -21,22 +20,8 @@ init_logger(level='INFO')
 logger = get_logger(__name__)
 
 def tensor2img(tensor, out_type=np.uint8, min_max=(0, 1)):
-    """Convert torch Tensors into image numpy arrays. from: mmedit/core/misc.py
-
-    After clamping to (min, max), image values will be normalized to [0, 1].
-
-    For differnet tensor shapes, this function will have different behaviors:
-
-        1. 4D mini-batch Tensor of shape (N x 3/1 x H x W):
-            Use `make_grid` to stitch images in the batch dimension, and then
-            convert it to numpy array.
-        2. 3D Tensor of shape (3/1 x H x W) and 2D Tensor of shape (H x W):
-            Directly change to numpy array.
-
-    Note that the image channel in input tensors should be RGB order. This
-    function will convert it to cv2 convention, i.e., (H x W x C) with BGR
-    order.
-
+    """Convert torch Tensors into image numpy arrays. 
+    
     Args:
         tensor (Tensor | list[Tensor]): Input tensors.
         out_type (numpy type): Output types. If ``np.uint8``, transform outputs
@@ -58,10 +43,6 @@ def tensor2img(tensor, out_type=np.uint8, min_max=(0, 1)):
         tensor = [tensor]
     result = []
     for _tensor in tensor:
-        # Squeeze two times so that:
-        # 1. (1, 1, h, w) -> (h, w) or
-        # 3. (1, 3, h, w) -> (3, h, w) or
-        # 2. (n>1, 3/1, h, w) -> (n>1, 3/1, h, w)
         _tensor = _tensor.squeeze(0).squeeze(0)
         _tensor = _tensor.float().detach().cpu().clamp_(*min_max)
         _tensor = (_tensor - min_max[0]) / (min_max[1] - min_max[0])
@@ -118,8 +99,6 @@ def psnr(img1, img2, crop_border=0, input_order='HWC', convert_to=None):
 
     img1, img2 = img1.astype(np.float32), img2.astype(np.float32)
     if isinstance(convert_to, str) and convert_to.lower() == 'y':
-        # img1 = mmcv.bgr2ycbcr(img1 / 255., y_only=True) * 255.
-        # img2 = mmcv.bgr2ycbcr(img2 / 255., y_only=True) * 255.
         img1 = cv.cvtColor(	img1 / 255,cv2.COLOR_BGR2YCrCb) * 255.
         img2 = cv.cvtColor(	img2 / 255,cv2.COLOR_BGR2YCrCb) * 255.
     elif convert_to is not None:
@@ -132,15 +111,12 @@ def psnr(img1, img2, crop_border=0, input_order='HWC', convert_to=None):
 
     mse_value = np.mean((img1 - img2)**2)
     if mse_value == 0:
-        # return float('inf')
         return float(10e5)
     return 20. * np.log10(255. / np.sqrt(mse_value))
 
 def _ssim(img1, img2):
     """Calculate SSIM (structural similarity) for one channel images.
 
-    It is called by func:`calculate_ssim`.
-
     Args:
         img1, img2 (ndarray): Images with range [0, 255] with order 'HWC'.
 
@@ -174,15 +150,6 @@ def _ssim(img1, img2):
 def ssim(img1, img2, crop_border=0, input_order='HWC', convert_to=None):
     """Calculate SSIM (structural similarity).
 
-    Ref:
-    Image quality assessment: From error visibility to structural similarity
-
-    The results are the same as that of the official released MATLAB code in
-    https://ece.uwaterloo.ca/~z70wang/research/ssim/.
-
-    For three-channel images, SSIM is calculated for each channel and then
-    averaged.
-
     Args:
         img1 (ndarray): Images with range [0, 255].
         img2 (ndarray): Images with range [0, 255].
@@ -210,8 +177,6 @@ def ssim(img1, img2, crop_border=0, input_order='HWC', convert_to=None):
 
     if isinstance(convert_to, str) and convert_to.lower() == 'y':
         img1, img2 = img1.astype(np.float32), img2.astype(np.float32)
-        # img1 = mmcv.bgr2ycbcr(img1 / 255., y_only=True) * 255.
-        # img2 = mmcv.bgr2ycbcr(img2 / 255., y_only=True) * 255.
         img1 = cv.cvtColor(	img1 / 255,cv2.COLOR_BGR2YCrCb) * 255.
         img2 = cv.cvtColor(	img2 / 255,cv2.COLOR_BGR2YCrCb) * 255.
         img2 = cv2.COLOR_BGR2YCrCb()
@@ -305,9 +270,9 @@ class QuantizationLoader(DataLoader):
             gtframes = np.array(gt_list)
             gtframes = np.expand_dims(gtframes,0)
             gtframes = gtframes.astype(np.float32)/255.
-            return inputframes,gtframes  # AccuracyawareQuantization, cross check
+            return inputframes,gtframes  
         
-        return inputframes,None  # DefaultQuantization
+        return inputframes,None  
 
 class BasicvsrMetrics(Metric):
     def __init__(self,metrics_name,quantization=True):
@@ -344,10 +309,10 @@ class BasicvsrMetrics(Metric):
 
         """
         if self.for_accuracy_aware_quantization:
-            output = torch.from_numpy(output[0])  # dim=4: (n,c,h,w) # for accuracy-aware quantization
+            output = torch.from_numpy(output[0])  
             target = torch.from_numpy(target[0])
         else:
-            output = torch.from_numpy(output)     # dim=5: (b,n,c,h,w) # for basicVSR_infer
+            output = torch.from_numpy(output)     
             target = torch.from_numpy(target)
         for metric in self._metrics:
             assert metric in self.allowed_metrics, (
@@ -464,7 +429,7 @@ def main(args):
                 "name": "DefaultQuantization",
                 "params": {
                     "target_device": "CPU",
-                    "stat_subset_size": 10,  # for default algorithm
+                    "stat_subset_size": 10,  
                 },
             }
         ]
@@ -478,7 +443,6 @@ def main(args):
     # Step 1: Load model
     model = load_model(model_config=model_config)
 
-    import pdb;pdb.set_trace() # @longkun:
     # Step 2: Initialize the engine
     if args.accuracy_aware_quantization:
         data_loader = QuantizationLoader(args.dataset_path,LR_or_HR=['LR','HR'],sub_folder=args.sub_folder,num_input_frames=args.nif,need_gt=True)  
-- 
2.25.1

