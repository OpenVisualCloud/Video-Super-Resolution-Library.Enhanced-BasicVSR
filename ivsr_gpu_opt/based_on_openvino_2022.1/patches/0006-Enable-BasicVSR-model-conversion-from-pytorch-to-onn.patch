From a17969a0e9731b34a42443dc72a1703247d09e09 Mon Sep 17 00:00:00 2001
From: YanjiePa <yanjie.pan@intel.com>
Date: Wed, 21 Sep 2022 14:55:35 +0800
Subject: [PATCH 06/17] Enable BasicVSR model conversion from pytorch to onnx
 (#3)

* Modify pytorch2onnx.py and add all related files to convert a BasicVSR model from pytorch to onnx.

Signed-off-by: Pan, Yanjie <yanjie.pan@intel.com>

* Add custom op readme from Kun.

Signed-off-by: Pan, Yanjie <yanjie.pan@intel.com>

* Add flow_warp custom op for pytorch.

Signed-off-by: Pan, Yanjie <yanjie.pan@intel.com>

* Code refactor to support both w/ and w/o flow_warp custom op.

Signed-off-by: Pan, Yanjie <yanjie.pan@intel.com>

Signed-off-by: Pan, Yanjie <yanjie.pan@intel.com>
---
 vsr_opt/Custom op from Pytorch to OpenVINO.md | 511 ++++++++++++++++++
 vsr_opt/configs/basicvsr_x2_cuc.py            |  17 +
 vsr_opt/flow_warp_pytorch_op/flow_warp_op.cpp | 482 +++++++++++++++++
 vsr_opt/flow_warp_pytorch_op/setup.py         |   9 +
 vsr_opt/mmedit/__init__.py                    |  34 ++
 vsr_opt/mmedit/models/__init__.py             |  15 +
 vsr_opt/mmedit/models/backbones/__init__.py   |   6 +
 .../models/backbones/sr_backbones/__init__.py |   7 +
 .../backbones/sr_backbones/basicvsr_net.py    | 432 +++++++++++++++
 vsr_opt/mmedit/models/base.py                 | 105 ++++
 vsr_opt/mmedit/models/builder.py              |  60 ++
 vsr_opt/mmedit/models/common/__init__.py      |  10 +
 vsr_opt/mmedit/models/common/flow_warp.py     |  65 +++
 .../mmedit/models/common/sr_backbone_utils.py |  97 ++++
 vsr_opt/mmedit/models/common/upsample.py      |  51 ++
 vsr_opt/mmedit/models/losses/__init__.py      |   5 +
 .../mmedit/models/losses/pixelwise_loss.py    | 221 ++++++++
 vsr_opt/mmedit/models/losses/utils.py         | 115 ++++
 vsr_opt/mmedit/models/registry.py             |   8 +
 vsr_opt/mmedit/models/restorers/__init__.py   |   7 +
 .../mmedit/models/restorers/basic_restorer.py | 211 ++++++++
 vsr_opt/mmedit/models/restorers/basicvsr.py   | 224 ++++++++
 vsr_opt/mmedit/version.py                     |  18 +
 vsr_opt/tools/pytorch2onnx.py                 |  92 +++-
 24 files changed, 2789 insertions(+), 13 deletions(-)
 create mode 100644 vsr_opt/Custom op from Pytorch to OpenVINO.md
 create mode 100644 vsr_opt/configs/basicvsr_x2_cuc.py
 create mode 100644 vsr_opt/flow_warp_pytorch_op/flow_warp_op.cpp
 create mode 100644 vsr_opt/flow_warp_pytorch_op/setup.py
 create mode 100644 vsr_opt/mmedit/__init__.py
 create mode 100644 vsr_opt/mmedit/models/__init__.py
 create mode 100644 vsr_opt/mmedit/models/backbones/__init__.py
 create mode 100644 vsr_opt/mmedit/models/backbones/sr_backbones/__init__.py
 create mode 100644 vsr_opt/mmedit/models/backbones/sr_backbones/basicvsr_net.py
 create mode 100644 vsr_opt/mmedit/models/base.py
 create mode 100644 vsr_opt/mmedit/models/builder.py
 create mode 100644 vsr_opt/mmedit/models/common/__init__.py
 create mode 100644 vsr_opt/mmedit/models/common/flow_warp.py
 create mode 100644 vsr_opt/mmedit/models/common/sr_backbone_utils.py
 create mode 100644 vsr_opt/mmedit/models/common/upsample.py
 create mode 100644 vsr_opt/mmedit/models/losses/__init__.py
 create mode 100644 vsr_opt/mmedit/models/losses/pixelwise_loss.py
 create mode 100644 vsr_opt/mmedit/models/losses/utils.py
 create mode 100644 vsr_opt/mmedit/models/registry.py
 create mode 100644 vsr_opt/mmedit/models/restorers/__init__.py
 create mode 100644 vsr_opt/mmedit/models/restorers/basic_restorer.py
 create mode 100644 vsr_opt/mmedit/models/restorers/basicvsr.py
 create mode 100644 vsr_opt/mmedit/version.py

diff --git a/vsr_opt/Custom op from Pytorch to OpenVINO.md b/vsr_opt/Custom op from Pytorch to OpenVINO.md
new file mode 100644
index 0000000000..bdf4710e35
--- /dev/null
+++ b/vsr_opt/Custom op from Pytorch to OpenVINO.md	
@@ -0,0 +1,511 @@
+# Custom op registeration and implementation from Pytorch to OpenVINO
+
+## Create Pytorch Custom op
+
+1.Adding the custom operator implementation in C++ 
+
+2.Registering custom operator with TorchScript
+
+3.Using the custom operator in programs
+
+If you have a custom operator that you need to register in TorchScript as a C++ extension, you need to implement the operator and build it with setuptools.
+
+Implement the custom operator `flow_warp` and register the custom operator in TorchScript by `torch::RegisterOperators` in `flow_warp.cpp`.
+```c
+// flow_warp_op.cpp
+#include <torch/script.h>
+...
+torch::Tensor flow_warp(torch::Tensor X,torch::Tensor flow) {
+    // flow_warp operator implmentation
+    ...
+}
+// register flow_warp op with TorchScript compiler 
+static auto registry = torch::RegisterOperators("custom_op_namespace::flow_warp", &flow_warp);
+```
+Note that the first argument of `torch::RegisterOperators` is operator **namespace** and **name** separated by **::**. The next argument is a reference to your function.
+
+Once you have your C++ function, you can build it using `setuptools.Extension`. Create a `setup.py` script in the same directory where you have your C++ code. `CppExtension.BuildExtension` takes care of the required compiler flags, such as required include paths and flags required during mixed C++/CUDA mixed compilation.
+
+
+```python
+# setup.py
+from setuptools import setup
+from torch.utils import cpp_extension
+
+setup(name='flow_warp',
+      ext_modules=[cpp_extension.CppExtension('flow_warp', ['flow_warp_op.cpp'])],
+      license='Apache License v2.0',
+      cmdclass={'build_ext': cpp_extension.BuildExtension})
+```
+Running the command `python setup.py build` from your source directory, you can build and install your extension. The shared object should be generated under build directory. In my example, the shared object is `./build/lib.linux-x86_64-3.9/flow_warp.cpython-39-x86_64-linux-gnu.so`
+
+Now, you can use the custom operator in your Pytorch code by loading the share object `torch.ops.load_library("./build/lib.linux-x86_64-3.9/flow_warp.cpython-39-x86_64-linux-gnu.so")` and referring to your custom operator: `torch.ops.<namespace_name>.<operator_name>` e.g. torch.ops.custom_op_namespace.flow_warp. The namespace and operator name is determind in `torch::RegisterOperators`
+
+```python
+# flow_warp_test.py
+import torch
+from torch.onnx import register_custom_op_symbolic
+class FlowWarpModel(torch.nn.Module):
+    def forward(self, x, flow):
+        # call custom operator
+        return torch.ops.custom_op_namespace.flow_warp(x, flow)
+
+if __name__ == '__main__':
+    x = torch.randn((1,1,5,5))
+    flow = torch.randn((1,5,5,2))
+    model = FlowWarpModel()
+    # load the share object
+    torch.ops.load_library("flow_warp_pytorch_op/build/lib.linux-x86_64-3.8/flow_warp.cpython-38-x86_64-linux-gnu.so")
+    output = model(x,flow)
+```
+
+## Expert the Pytorch custom op to ONNX
+
+You can export your custom operator using existing ONNX ops, or you can create custom ONNX ops to use. In both cases, you need to **add the symbolic method to the exporter**, and **register your custom symbolic** using `torch.onnx.register_custom_op_symbolic`.
+
+In our example, we intend to create the custom operator by our own. We also add the registeration script in the python file `flow_warp_test.py`
+
+```python
+# flow_warp_test.py
+# from torch.onnx.symbolic_helper import parse_args
+# @parse_args("v", "v")
+def my_flow_warp(g, input, flow):
+    return g.op("custom_op::flow_warp", input, flow)
+
+from torch.onnx import register_custom_op_symbolic
+register_custom_op_symbolic("custom_op_namespace::flow_warp", my_flow_warp, 11)
+```
+`g.op()` registers the custom operator symbolic in ONNX. The first argument is `<domain>::<custom_op_name>`.
+
+`register_custom_op_symbolic` function passes `<namespace_in_pytorch>::<custom_op_name>` in Pytorch to `<custom_op_domain_in_onnx>::<custom_op_name>` in ONNX. Note that the namespace/domain and custom operator name can be different in Pytorch and ONNX.
+
+Now, export the custom operator to ONNX using `torch.onnx.export`.
+```python
+# flow_warp_test.py
+import torch
+# from torch.onnx.symbolic_helper import parse_args
+# @parse_args("v", "v")
+def my_flow_warp(g, input, flow):
+    return g.op("custom_op::flow_warp", input, flow)
+
+from torch.onnx import register_custom_op_symbolic
+register_custom_op_symbolic("custom_op_namespace::flow_warp", my_flow_warp, 11)
+
+
+from torch.onnx import register_custom_op_symbolic
+class FlowWarpModel(torch.nn.Module):
+    def forward(self, x, flow):
+        return torch.ops.custom_op_namespace.flow_warp(x, flow)
+
+
+def exprt_to_onnx(model,inputs):
+    # export pytorch model to onnx model with custom operator
+    torch.onnx.export(model,inputs,'FlowWarp.onnx',opset_version=11,
+        input_names=["input", "flow"], 
+        output_names=["ouput"],custom_opsets={"custom_op": 11})
+    print('Successfully export FlowWarp.onnx')
+
+
+if __name__ == '__main__':
+    x = torch.randn((1,1,5,5))
+    flow = torch.randn((1,5,5,2))
+    model = FlowWarpModel()
+    # load the share object
+    torch.ops.load_library("flow_warp_pytorch_op/build/lib.linux-x86_64-3.8/flow_warp.cpython-38-x86_64-linux-gnu.so")
+    output = model(x,flow)
+    inputs = (x,flow)
+    # export the custom operator to onnx
+    export_to_onnx(model,inputs)
+```
+
+## Implement the custom op in ONNX runtime
+
+The next step is to implement this operator in ONNX Runtime and build it to a library. For this step, you need to have ONNX Runtime installed on your system.
+
+In order to implement the custom operator in ONNX runtime, you need to create a **custom operator object** and write it's **kernel implementations**, and **add it to your custom domain**. In our example we create a script named `flow_warp_op.h` to define the custom operation object and kernel definition.
+
+```c
+// flow_warp_op.h
+#ifndef ONNXRUNTIME_FLOWWARP_H
+#define ONNXRUNTIME_FLOWWARP_H
+
+#include <onnxruntime_cxx_api.h>
+
+// custom operator kernel define
+struct FlowWarpKernel {
+  FlowWarpKernel(OrtApi api, const OrtKernelInfo *info);
+  void Compute(OrtKernelContext *context);
+
+protected:
+  OrtApi api_;
+  Ort::CustomOpApi ort_;
+  const OrtKernelInfo *info_;
+  Ort::AllocatorWithDefaultOptions allocator_;
+};
+
+// custom operator object
+struct FlowWarpOp : Ort::CustomOpBase<FlowWarpOp, FlowWarpKernel> {
+  void *CreateKernel(OrtApi api, const OrtKernelInfo *info) const {
+    return new FlowWarpKernel(api, info);
+  };
+
+  const char *GetName() const { return "flow_warp"; };
+
+  size_t GetInputTypeCount() const { return 2; };
+  ONNXTensorElementDataType GetInputType(size_t /*index*/) const {
+    return ONNX_TENSOR_ELEMENT_DATA_TYPE_FLOAT;
+  };
+
+  size_t GetOutputTypeCount() const { return 1; };
+  ONNXTensorElementDataType GetOutputType(size_t /*index*/) const {
+    return ONNX_TENSOR_ELEMENT_DATA_TYPE_FLOAT;
+  };
+
+  const char *GetExecutionProviderType() const {
+    return "CPUExecutionProvider";
+  };
+};
+#endif
+```
+
+The implementation is write in `flow_warp_op.cc`.
+```c
+#include <iostream>
+#include "flow_warp_op.h"
+struct OrtTensorDimensions : std::vector<int64_t> {
+  OrtTensorDimensions(Ort::CustomOpApi ort, const OrtValue* value) {
+    OrtTensorTypeAndShapeInfo* info = ort.GetTensorTypeAndShape(value);
+    std::vector<int64_t>::operator=(ort.GetTensorShape(info));
+    ort.ReleaseTensorTypeAndShapeInfo(info);
+  }
+};
+
+FlowWarpKernel::FlowWarpKernel(OrtApi api, const OrtKernelInfo *info):api_(api),
+        ort_(api_),info_(info)
+{
+  allocator_ = Ort::AllocatorWithDefaultOptions();
+}
+
+void FlowWarpKernel::Compute(OrtKernelContext *context) {
+    // flow_warp operator implementation
+    ...
+}
+```
+Once you have the custom kernel and schema, you can add them to the domain using the C API. In our example, we create a register function in `register_op.h` and implement the function in source file `register_op.cpp`.
+
+```c
+// registor_op.h
+#ifndef ONNXRUNTIME_CUSTOM_OP_REGISTER_H
+#define ONNXRUNTIME_CUSTOM_OP_REGISTER_H
+#include <onnxruntime_c_api.h>
+
+#ifdef __cplusplus
+extern "C" {
+#endif
+
+OrtStatus *ORT_API_CALL RegisterCustomOps(OrtSessionOptions *options,
+                                          const OrtApiBase *api);
+
+#ifdef __cplusplus
+}
+#endif
+#endif  // ONNXRUNTIME_REGISTER_H
+```
+
+```c
+// register_op.cpp
+#include "flow_warp_op.h"
+#include <iostream>
+#include "onnxruntime_cxx_api.h"
+#include "register_op.h"
+
+FlowWarpOp c_FlowWarpOp;
+
+OrtStatus *ORT_API_CALL RegisterCustomOps(OrtSessionOptions *options,
+                                          const OrtApiBase *api) {
+    OrtCustomOpDomain *domain = nullptr;
+    const OrtApi *ortApi = api->GetApi(ORT_API_VERSION);
+    if (auto status = ortApi->CreateCustomOpDomain("custom_op", &domain)) {
+        return status;
+    }
+
+    // AddOrtCustomOpDomainToContainer(domain, ortApi);
+
+    if (auto status = ortApi->CustomOpDomain_Add(domain, &c_FlowWarpOp)) {
+        return status;
+    }
+
+    return ortApi->AddCustomOpDomain(options, domain); 
+  }
+
+```
+
+In the register function, you need to create a custom domain and add it to the api. This domain name is the same name provided in the symbolic method when exporting the model. Also this domain name is same with the domain name in ONNX. In our example, the domain name is `custom_op`. Note that the custom operator object should be a **global** variant, in case of scope failure.
+
+Now, you need to create a `CMakeLists.txt` to build the custom operator implmentation to a share library.
+
+Once you have the cmake file, create a build directory from the same location by command `mkdir build` and get in the directory by `cd build`. Execute the command `cmake ..` to configure the project and build it using `make` command.
+
+```cmake
+# CMakeLists.txt
+cmake_minimum_required(VERSION 3.10)
+project (FlowWarp_op)
+add_definitions(-std=c++11 -g)
+
+set(SOURCE flow_warp_op.cc register_op.cpp)
+set(HEADER flow_warp_op.h register_op.h)
+set(TEST_SOURCE "")
+add_library(FlowWarp_op SHARED ${SOURCE} ${HEADER} ${TEST_SOURCE})
+
+#Include path to header files for Custom Op
+include_directories("/home/media/xxx/basicvsr/custom_op/ort_custom_op/download/build/native/include/")
+
+#Linking dependencies for Custom Op
+find_library(ONNXRUNTIME_LIBRARY onnxruntime HINTS "/home/media/xxx/basicvsr/custom_op/ort_custom_op/download/runtimes/linux-x64/native")
+target_link_libraries(FlowWarp_op PUBLIC ${ONNXRUNTIME_LIBRARY})
+```
+
+Now that you have implmented the custom operator, you should be able to run your model and test it. Before running, you need to register the custom operator to onnxruntime sessions by the share library using `register_custom_ops_library`.
+
+```py
+def inference_on_onnx(x,flow):
+    ort_custom_op_path= "./flow_warp_onnxruntime_op/build/libFlowWarp_op.so"
+    onnx_file = 'FlowWarp.onnx'
+    session_options = ort.SessionOptions()
+    if ort_custom_op_path:
+        # register the custom operation
+        session_options.register_custom_ops_library(ort_custom_op_path)
+    
+    sess = ort.InferenceSession(onnx_file, session_options)
+    ort_result = sess.run(None, {
+        'input': x.detach().numpy(),
+        'flow': flow.detach().numpy()
+    })
+    return ort_result
+```
+The code fragment above can be added to the test file `flow_warp_test.py`.
+
+ [Reference:How to export Pytorch model with custom op to ONNX and run it in ONNX Runtime](https://github.com/onnx/tutorials/tree/master/PyTorchCustomOperator)
+
+
+## Expert ONNX custom operator to OpenVINO IR and implement for OpenVINO runtime
+
+AS the OpenVINO offical documents [Custom Operation Support Overview](https://docs.openvino.ai/2021.4/openvino_docs_HOWTO_Custom_Layers_Guide.html#enabling-magnetic-resonance-image-reconstruction-model) informed, there are three steps to support inference of a model with custom operation(s):
+
+Step1: Add support for custom operation in the Model Optimizer
+
+Step2: Create custom operation as nGraph operation.
+
+Step3: Create the custom operation implementation for Inference Engine.
+
+
+
+### Add support for custom in the Model Optimizer
+[Model Optimizer Extensibility](https://docs.openvino.ai/latest/openvino_docs_MO_DG_prepare_model_customize_model_optimizer_Customize_Model_Optimizer.html#model-optimizer-extensions)
+
+You may refer to the [Model Optimizer Workflow](https://docs.openvino.ai/2020.1/_docs_HOWTO_Custom_Layers_Guide.html) and you can find that there are two keys to extend the custom layers in Model Optimizer:
+- Custom Layer Extractor
+- Custom Layer Operation
+
+In order to extend the custom operation in Model Optimizer, you need to make a directory in the openvino mo path `openvino/tools/mo/openvino/tools/mo` and define the custom layer extractor and operation. In our example, we make a directory `my_custom_op` and further make two sub-directories `front/onnx` and `ops`. We create `flow_warp_custom_op_ext.py` in `front/onnx` and `flow_warp_custom_op.py` in `ops`. [Example of Extractor and Operation](https://docs.openvino.ai/2021.4/openvino_docs_MO_DG_prepare_model_customize_model_optimizer_Customize_Model_Optimizer.html#extensions)
+
+```py
+# flow_warp_custom_op_ext.py
+
+from mo.front.extractor import FrontExtractorOp
+from mo.ops.op import Op
+from mo.my_mo_extensions.ops.flow_warp_custom_op import FlowWarp
+class FlowWarpFrontExtractor(FrontExtractorOp):
+    op = 'flow_warp'
+    enabled = True
+
+    @classmethod
+    def extract(cls, node):
+        attrs = {}
+        FlowWarp.update_node_stat(node,attrs)
+
+        return cls.enabled
+```
+
+```py
+# flow_warp_custom_op.py
+
+import numpy as np
+from openvino.tools.mo.graph.graph import Node, Graph
+from openvino.tools.mo.ops.op import Op
+class FlowWarp(Op):
+    op = 'flow_warp'
+    def __init__(self, graph, attrs):
+        mandatory_props = {
+            'type': self.op,  
+            'op': self.op,   
+            'infer': self.infer
+        }
+        super().__init__(graph, mandatory_props, attrs)
+    
+    @staticmethod
+    def infer(node):
+        node_name = node.soft_get('name', node.id)
+        input_shape = node.in_port(0).data.get_shape()
+        assert input_shape is not None, 'Input shape is None for node "{}"'.format(node_name)
+        node.out_port(0).data.set_shape(input_shape)
+```
+Theoretically, you can transform the ONNX model to OpenVINO IR successfully by the custom layer extractor and operation. However, in the more recently release OpenVINO source code, there would be nGraph validation in the MO process. That means the MO process would produce an temporary IR and try to build the model graph to validate the IR is workable. The validation process would meet some mistakes, you can find the solution latter.
+
+
+### Create custom operation as nGraph operation
+There is the offical documents about create custom operation as nGraph operation
+[Custom nGraph Operations](https://docs.openvino.ai/2021.4/openvino_docs_IE_DG_Extensibility_DG_AddingNGraphOps.html#doxid-openvino-docs-i-e-d-g-extensibility-d-g-adding-n-graph-ops).
+
+Actually, you can find a example of custom operator extension in the OpenVINO source code in the path: `openvino/docs/template_extension/`. There are two kinds of template in the directory and the old one is the same as the documents described. However, the old one may not work in the new release (2022.1 in our example). In our example, we try the new one.
+
+You need to define your namespace and your custom operator object which should inherit from `ov::op::OP`. In our example, we create `flow_warp_custom_op.h` to define the `FlowWarp` operator. As for some override functions you may refer to [Custom nGraph Operations](https://docs.openvino.ai/2021.4/openvino_docs_IE_DG_Extensibility_DG_AddingNGraphOps.html#doxid-openvino-docs-i-e-d-g-extensibility-d-g-adding-n-graph-ops).
+
+```cpp
+// flow_warp_custom_op.h
+#pragma once
+
+//! [op:common_include]
+#include <openvino/op/op.hpp>
+//! [op:common_include]
+
+//! [op:header]
+namespace CustomExtension {
+
+class FlowWarp : public ov::op::Op {
+public:
+    OPENVINO_OP("flow_warp");
+
+    FlowWarp() = default;
+    FlowWarp(const ov::Output<ov::Node>& input,const ov::Output<ov::Node>& flow);
+    void validate_and_infer_types() override;
+    std::shared_ptr<ov::Node> clone_with_new_inputs(const ov::OutputVector& new_args) const override;
+    bool visit_attributes(ov::AttributeVisitor& visitor) override;
+
+    bool evaluate(ov::TensorVector& outputs, const ov::TensorVector& inputs) const override;
+    bool has_evaluate() const override;
+};
+//! [op:header]
+
+}  // namespace TemplateExtension
+
+```
+The implmentation is in the source file `flow_warp_custom_op.cpp`.
+```cpp
+//flow_warp_custom_op.cpp
+
+#include "flow_warp_custom_op.h"
+using namespace CustomExtension;
+
+//! [op:ctor]
+FlowWarp::FlowWarp(const ov::Output<ov::Node>& input,const ov::Output<ov::Node>& flow) : Op({input,flow}) {
+    constructor_validate_and_infer_types();
+}
+//! [op:ctor]
+
+//! [op:validate]
+void FlowWarp::validate_and_infer_types() {
+    // Operation doesn't change shapes end element type
+    set_output_type(0, get_input_element_type(0), get_input_partial_shape(0));
+}
+//! [op:validate]
+
+//! [op:copy]
+std::shared_ptr<ov::Node> FlowWarp::clone_with_new_inputs(const ov::OutputVector& new_args) const {
+    OPENVINO_ASSERT(new_args.size() == 2, "Incorrect number of new arguments");
+
+    return std::make_shared<FlowWarp>(new_args.at(0),new_args.at(1));
+}
+//! [op:copy]
+
+//! [op:visit_attributes]
+bool FlowWarp::visit_attributes(ov::AttributeVisitor& visitor) {
+    return true;
+}
+//! [op:visit_attributes]
+
+//! [op:evaluate]
+bool FlowWarp::evaluate(ov::TensorVector& outputs, const ov::TensorVector& inputs) const {
+    // flow_warp custom operator implementation
+    ...
+    return true;
+}
+
+bool FlowWarp::has_evaluate() const {
+    return true;
+}
+//! [op:evaluate]
+```
+Note that in the new custom extension method the `execute` function is the entrance for kernel to perform the custom operator's operation. Therefore, the Step 3 "Create the custom operation for Inference Engine" can be merged into Step 2.
+
+After defining and implmenting the custom operator, the next step is to register the custom operation. You may register the custom operation by create the custom operation as an extension. In our example, we create a script file `extension.cpp` to register custom operation as an extension. In the script you need to define two share pointer on behalf of the operation itself and the operation mapping.
+
+```cpp
+// extension.cpp
+
+// Copyright (C) 2018-2022 Intel Corporation
+// SPDX-License-Identifier: Apache-2.0
+
+#include <openvino/core/extension.hpp>
+#include <openvino/core/op_extension.hpp>
+#include <openvino/frontend/extension.hpp>
+
+#include "flow_warp_custom_op.h"
+
+// clang-format off
+//! [ov_extension:entry_point]
+OPENVINO_CREATE_EXTENSIONS(
+    std::vector<ov::Extension::Ptr>({
+
+        // Register operation itself, required to be read from IR
+        std::make_shared<ov::OpExtension<CustomExtension::FlowWarp>>(),
+
+        // Register operaton mapping, required when converted from framework model format
+        std::make_shared<ov::frontend::OpExtension<CustomExtension::FlowWarp>>()
+    }));
+//! [ov_extension:entry_point]
+// clang-format on
+
+```
+Now, you can build the custom operation souce code into a share library by `CMakeLists.txt`.
+```cmake
+# Copyright (C) 2018-2022 Intel Corporation
+# SPDX-License-Identifier: Apache-2.0
+
+# [cmake:extension]
+set(CMAKE_CXX_STANDARD 11)
+
+set(TARGET_NAME "custom_extension")
+
+find_package(OpenVINO)
+
+set(SRC flow_warp_custom_op.cpp extension.cpp flow_warp.cpp)
+
+add_library(${TARGET_NAME} MODULE ${SRC})
+
+target_compile_definitions(${TARGET_NAME} PRIVATE IMPLEMENT_OPENVINO_EXTENSION_API)
+target_link_libraries(${TARGET_NAME} PRIVATE openvino::runtime)
+```
+
+Since we have acqured the custom operation share library, we can add extension for nGraph validation in MO process. In our example, to address the nGraph validation problem, we make some modification in the `openvino/tools/mo/openvino/tools/mo/back/offline_transformations.py` by adding the custom extension by library path manually.
+```py
+# offline_transformations.py
+
+    def read_model(path_to_xml):
+        fe = fem.load_by_framework(framework="ir")
+        # add custom extension for nGraph validation 
+        fe.add_extension('/home/media/xxx/openvino/src/my_custom_op/build/libcustom_extension.so')  # addin
+        function = fe.convert(fe.load(path_to_xml))
+        return function
+```
+
+After obtaining the IR format in success, you can use the custom operation in your scene by loading the custom operation share library as extension. You can add the code fragments below in your right position.
+
+```py
+from openvino.runtime import Core
+ie=Core()
+ie.add_extension('/home/media/xxx/openvino/bin/intel64/Release/lib/libcustom_extension.so') 
+```
+
+
+
diff --git a/vsr_opt/configs/basicvsr_x2_cuc.py b/vsr_opt/configs/basicvsr_x2_cuc.py
new file mode 100644
index 0000000000..ebba1c4b13
--- /dev/null
+++ b/vsr_opt/configs/basicvsr_x2_cuc.py
@@ -0,0 +1,17 @@
+exp_name = 'basicvsr_x2_cuc'
+
+# model settings
+model = dict(
+    type='BasicVSR',
+    generator=dict(
+        type='BasicVSRNet',
+        scale=2,
+        mid_channels=64,
+        num_blocks=8,
+        spynet_pretrained='https://download.openmmlab.com/mmediting/restorers/'
+                          'basicvsr/spynet_20210409-c6c1bd09.pth',
+        custom_op=False),
+    pixel_loss=dict(type='CharbonnierLoss', loss_weight=1.0, reduction='mean'))
+# model training and testing settings
+train_cfg = dict(fix_iter=5000)
+test_cfg = dict(metrics=[], crop_border=0)
diff --git a/vsr_opt/flow_warp_pytorch_op/flow_warp_op.cpp b/vsr_opt/flow_warp_pytorch_op/flow_warp_op.cpp
new file mode 100644
index 0000000000..4441e39ba0
--- /dev/null
+++ b/vsr_opt/flow_warp_pytorch_op/flow_warp_op.cpp
@@ -0,0 +1,482 @@
+#include <torch/script.h>
+#include <vector>
+#include <iostream>
+#include <cmath>
+#define MIN(a, b) (((a) < (b)) ? (a) : (b))
+#define MAX(a, b) (((a) < (b)) ? (b) : (a))
+#define CLIP_COORDINATES(in, out, clip_limit) \
+  out = MIN((clip_limit - 1), MAX(in, 0))
+
+enum GridSamplerInterpolation { Bilinear = 0, Nearest = 1, Bicubic = 2 };
+enum GridSamplerPadding { Zeros = 0, Border = 1, Reflection = 2 };
+
+template <typename scalar_t>
+static inline scalar_t grid_sampler_unnormalize(scalar_t coord, int64_t size,
+                                                bool align_corners) {
+  if (align_corners) {
+    return ((coord + 1) / 2) * (size - 1);
+  } else {
+    return ((coord + 1) * size - 1) / 2;
+  }
+}
+
+// Clips coordinates to between 0 and clip_limit - 1
+template <typename scalar_t>
+static inline scalar_t clip_coordinates(scalar_t in, int64_t clip_limit) {
+  return std::min(static_cast<scalar_t>(clip_limit - 1),
+                  std::max(in, static_cast<scalar_t>(0)));
+}
+
+// Reflects coordinates until they fall between low and high (inclusive).
+// The bounds are passed as twice their value so that half-integer values
+// can be represented as ints.
+template <typename scalar_t>
+static inline scalar_t reflect_coordinates(scalar_t in, int64_t twice_low,
+                                           int64_t twice_high) {
+  if (twice_low == twice_high) {
+    return static_cast<scalar_t>(0);
+  }
+  scalar_t min = static_cast<scalar_t>(twice_low) / 2;
+  scalar_t span = static_cast<scalar_t>(twice_high - twice_low) / 2;
+  in = std::fabs(in - min);
+  // `fmod` returns same sign as `in`, which is positive after the `fabs` above.
+  scalar_t extra = std::fmod(in, span);
+  int flips = static_cast<int>(std::floor(in / span));
+  if (flips % 2 == 0) {
+    return extra + min;
+  } else {
+    return span - extra + min;
+  }
+}
+
+template <typename scalar_t>
+static inline scalar_t compute_coordinates(scalar_t coord, int64_t size,
+                                           int64_t padding_mode,
+                                           bool align_corners) {
+  if (padding_mode == GridSamplerPadding::Border) {
+    coord = clip_coordinates(coord, size);
+  } else if (padding_mode == GridSamplerPadding::Reflection) {
+    if (align_corners) {
+      coord = reflect_coordinates(coord, 0, 2 * (size - 1));
+    } else {
+      coord = reflect_coordinates(coord, -1, 2 * size - 1);
+    }
+    coord = clip_coordinates(coord, size);
+  }
+  return coord;
+}
+
+// Computes the pixel source index value for a grid coordinate
+template <typename scalar_t>
+static inline scalar_t grid_sampler_compute_source_index(scalar_t coord,
+                                                         int64_t size,
+                                                         int64_t padding_mode,
+                                                         bool align_corners) {
+  coord = grid_sampler_unnormalize(coord, size, align_corners);
+  coord = compute_coordinates(coord, size, padding_mode, align_corners);
+  return coord;
+}
+
+static inline bool within_bounds_2d(int64_t h, int64_t w, int64_t H,
+                                    int64_t W) {
+  return h >= 0 && h < H && w >= 0 && w < W;
+}
+
+template <typename scalar_t>
+static inline scalar_t get_value_bounded(const scalar_t *data, scalar_t x,
+                                         scalar_t y, int64_t W, int64_t H,
+                                         int64_t sW, int64_t sH,
+                                         int64_t padding_mode,
+                                         bool align_corners) {
+  x = compute_coordinates(x, W, padding_mode, align_corners);
+  y = compute_coordinates(y, H, padding_mode, align_corners);
+
+  int64_t ix = static_cast<int64_t>(x);
+  int64_t iy = static_cast<int64_t>(y);
+
+  if (within_bounds_2d(iy, ix, H, W)) {
+    return data[iy * sH + ix * sW];
+  }
+  return static_cast<scalar_t>(0);
+}
+
+template <typename scalar_t>
+static inline scalar_t cubic_convolution1(scalar_t x, scalar_t A) {
+  return ((A + 2) * x - (A + 3)) * x * x + 1;
+}
+
+template <typename scalar_t>
+static inline scalar_t cubic_convolution2(scalar_t x, scalar_t A) {
+  return ((A * x - 5 * A) * x + 8 * A) * x - 4 * A;
+}
+
+template <typename scalar_t>
+static inline void get_cubic_upsample_coefficients(scalar_t coeffs[4],
+                                                   scalar_t t) {
+  scalar_t A = -0.75;
+
+  scalar_t x1 = t;
+  coeffs[0] = cubic_convolution2<scalar_t>(x1 + 1.0, A);
+  coeffs[1] = cubic_convolution1<scalar_t>(x1, A);
+
+  // opposite coefficients
+  scalar_t x2 = 1.0 - t;
+  coeffs[2] = cubic_convolution1<scalar_t>(x2, A);
+  coeffs[3] = cubic_convolution2<scalar_t>(x2 + 1.0, A);
+}
+
+template <typename scalar_t>
+static inline scalar_t cubic_interp1d(scalar_t x0, scalar_t x1, scalar_t x2,
+                                      scalar_t x3, scalar_t t) {
+  scalar_t coeffs[4];
+  get_cubic_upsample_coefficients<scalar_t>(coeffs, t);
+
+  return x0 * coeffs[0] + x1 * coeffs[1] + x2 * coeffs[2] + x3 * coeffs[3];
+}
+
+void bilinear_grid_sample(torch::Tensor X, torch::Tensor grid, torch::Tensor &output){
+    float* input_data = X.data_ptr<float>();
+    float* grid_data = grid.data_ptr<float>();
+    float* out_ptr = output.data_ptr<float>();
+    const bool align_corners = true;
+    const int64_t padding_mode = 0;  // padding_mode: zeros
+    const int64_t interpolation_mode = 0; // interpolation_mode: bilinear
+    int64_t N = X.size(0);
+    int64_t C = X.size(1);
+    int64_t inp_H = X.size(2);
+    int64_t inp_W = X.size(3);
+    int64_t /*grid_N = grid.size(0),*/grid_H = grid.size(1),grid_W = grid.size(2),grid_C = grid.size(3);
+    int64_t /*out_N = N,*/ out_C = C;
+    int64_t out_H = grid.size(1);
+    int64_t out_W =  grid.size(2);
+
+    int64_t inp_sN = C * inp_H * inp_W;//input_dims[1] * input_dims[2] * input_dims[3];
+    int64_t inp_sC = inp_H * inp_W;//input_dims[2] * input_dims[3];
+    int64_t inp_sH = inp_W;//input_dims[3];
+    int64_t inp_sW = 1;
+    int64_t grid_sN = grid_H * grid_W * grid_C;//grid_dims[1] * grid_dims[2] * grid_dims[3];
+    int64_t grid_sH = grid_W * grid_C;//grid_dims[2] * grid_dims[3];
+    int64_t grid_sW = grid_C;//grid_dims[3];
+    int64_t grid_sCoor = 1;
+    int64_t out_sN = out_C * out_H * out_W;//output_dims[1] * output_dims[2] * output_dims[3];
+    int64_t out_sC = out_H * out_W;//output_dims[2] * output_dims[3];
+    int64_t out_sH = out_W;//output_dims[3];
+    int64_t out_sW = 1;
+
+    // loop over each output pixel
+  for (int64_t n = 0; n < N; ++n) {
+    const float *grid_ptr_N = grid_data + n * grid_sN;
+    const float *inp_ptr_N = input_data + n * inp_sN;
+    for (int64_t h = 0; h < out_H; ++h) {
+      for (int64_t w = 0; w < out_W; ++w) {
+        const float *grid_ptr_NHW = grid_ptr_N + h * grid_sH + w * grid_sW;
+        float x = *grid_ptr_NHW;
+        float y = grid_ptr_NHW[grid_sCoor];
+
+        float ix = grid_sampler_compute_source_index(x, inp_W, padding_mode,
+                                                     align_corners);
+        float iy = grid_sampler_compute_source_index(y, inp_H, padding_mode,
+                                                     align_corners);
+
+        if (interpolation_mode == GridSamplerInterpolation::Bilinear) {
+          // get corner pixel values from (x, y)
+          // for 4d, we use north-east-south-west
+          int64_t ix_nw = static_cast<int64_t>(std::floor(ix));
+          int64_t iy_nw = static_cast<int64_t>(std::floor(iy));
+
+          int64_t ix_ne = ix_nw + 1;
+          int64_t iy_ne = iy_nw;
+
+          int64_t ix_sw = ix_nw;
+          int64_t iy_sw = iy_nw + 1;
+
+          int64_t ix_se = ix_nw + 1;
+          int64_t iy_se = iy_nw + 1;
+
+          // get surfaces to each neighbor:
+          float nw = (ix_se - ix) * (iy_se - iy);
+          float ne = (ix - ix_sw) * (iy_sw - iy);
+          float sw = (ix_ne - ix) * (iy - iy_ne);
+          float se = (ix - ix_nw) * (iy - iy_nw);
+
+          // calculate bilinear weighted pixel value and set output pixel
+          const float *inp_ptr_NC = inp_ptr_N;
+          float *out_ptr_NCHW = out_ptr + n * out_sN + h * out_sH + w * out_sW;
+          for (int64_t c = 0; c < C;
+               ++c, out_ptr_NCHW += out_sC, inp_ptr_NC += inp_sC) {
+            auto res = static_cast<float>(0);
+            if (within_bounds_2d(iy_nw, ix_nw, inp_H, inp_W)) {
+              res += inp_ptr_NC[iy_nw * inp_sH + ix_nw * inp_sW] * nw;
+            }
+            if (within_bounds_2d(iy_ne, ix_ne, inp_H, inp_W)) {
+              res += inp_ptr_NC[iy_ne * inp_sH + ix_ne * inp_sW] * ne;
+            }
+            if (within_bounds_2d(iy_sw, ix_sw, inp_H, inp_W)) {
+              res += inp_ptr_NC[iy_sw * inp_sH + ix_sw * inp_sW] * sw;
+            }
+            if (within_bounds_2d(iy_se, ix_se, inp_H, inp_W)) {
+              res += inp_ptr_NC[iy_se * inp_sH + ix_se * inp_sW] * se;
+            }
+            *out_ptr_NCHW = res;
+          }
+        } else if (interpolation_mode == GridSamplerInterpolation::Nearest) {
+          int64_t ix_nearest = static_cast<int64_t>(std::nearbyint(ix));
+          int64_t iy_nearest = static_cast<int64_t>(std::nearbyint(iy));
+
+          // assign nearest neighbor pixel value to output pixel
+          float *out_ptr_NCHW = out_ptr + n * out_sN + h * out_sH + w * out_sW;
+          const float *inp_ptr_NC = inp_ptr_N;
+          for (int64_t c = 0; c < C;
+               ++c, out_ptr_NCHW += out_sC, inp_ptr_NC += inp_sC) {
+            if (within_bounds_2d(iy_nearest, ix_nearest, inp_H, inp_W)) {
+              *out_ptr_NCHW =
+                  inp_ptr_NC[iy_nearest * inp_sH + ix_nearest * inp_sW];
+            } else {
+              *out_ptr_NCHW = static_cast<float>(0);
+            }
+          }
+        } else if (interpolation_mode == GridSamplerInterpolation::Bicubic) {
+          // grid_sampler_compute_source_index will "clip the value" of idx
+          // depends on the padding,
+          // which would cause calculation to be wrong,
+          // for example x = -0.1 -> ix = 0 for zero padding, but in bicubic ix
+          // = floor(x) = -1
+          // There would be more problem in reflection padding, since the -1 and
+          // +1 direction is not fixed in boundary condition
+          ix = grid_sampler_unnormalize(x, inp_W, align_corners);
+          iy = grid_sampler_unnormalize(y, inp_H, align_corners);
+
+          float ix_nw = std::floor(ix);
+          float iy_nw = std::floor(iy);
+
+          const float tx = ix - ix_nw;
+          const float ty = iy - iy_nw;
+
+          const float *inp_ptr_NC = inp_ptr_N;
+          float *out_ptr_NCHW = out_ptr + n * out_sN + h * out_sH + w * out_sW;
+          for (int64_t c = 0; c < C;
+               ++c, out_ptr_NCHW += out_sC, inp_ptr_NC += inp_sC) {
+            float coefficients[4];
+
+            // Interpolate 4 values in the x direction
+            for (int64_t i = 0; i < 4; ++i) {
+              coefficients[i] = cubic_interp1d<float>(
+                  get_value_bounded<float>(inp_ptr_NC, ix_nw - 1, iy_nw - 1 + i,
+                                           inp_W, inp_H, inp_sW, inp_sH,
+                                           padding_mode, align_corners),
+                  get_value_bounded<float>(inp_ptr_NC, ix_nw + 0, iy_nw - 1 + i,
+                                           inp_W, inp_H, inp_sW, inp_sH,
+                                           padding_mode, align_corners),
+                  get_value_bounded<float>(inp_ptr_NC, ix_nw + 1, iy_nw - 1 + i,
+                                           inp_W, inp_H, inp_sW, inp_sH,
+                                           padding_mode, align_corners),
+                  get_value_bounded<float>(inp_ptr_NC, ix_nw + 2, iy_nw - 1 + i,
+                                           inp_W, inp_H, inp_sW, inp_sH,
+                                           padding_mode, align_corners),
+                  tx);
+            }
+
+            // Interpolate in the y direction
+            *out_ptr_NCHW =
+                cubic_interp1d<float>(coefficients[0], coefficients[1],
+                                      coefficients[2], coefficients[3], ty);
+          }
+        }
+      }
+    }
+  }
+}
+
+
+torch::Tensor flow_warp(torch::Tensor X,torch::Tensor flow) {
+
+  int64_t N = X.size(0);
+  int64_t C = X.size(1);
+  int64_t inp_H = X.size(2);
+  int64_t inp_W = X.size(3);
+  int64_t out_H = flow.size(1);
+  int64_t out_W = flow.size(2);
+  auto flow_new = torch::zeros({flow.size(0),flow.size(1),flow.size(2),flow.size(3)}, at::kFloat);
+  flow_new = flow_new + flow;
+  // auto flow_clone = torch::clone(flow); // torch::clone 
+  float* input_data = X.data_ptr<float>();
+  float* flow_data = flow_new.data_ptr<float>();
+  auto output = torch::zeros({N,C,inp_H,inp_W}, at::kFloat);
+  // flow warp prehead
+  if(inp_H != out_H || inp_W != out_W){
+    std::cout << "The spatial sizes of input ("<<inp_H<<","<<inp_W<<")"<<" and flow ("<<out_H<<","<<out_W<<") are not the same."<<std::endl;
+    return output;
+  }
+
+  int64_t flow_sN = flow.size(1) * flow.size(2) * flow.size(3);//flow_dims[1] * flow_dims[2] * flow_dims[3];
+  int64_t flow_sH = flow.size(2)*flow.size(3);//flow_dims[2] * flow_dims[3];
+  int64_t flow_sW = flow.size(3); //flow_dims[3];
+  int64_t flow_sCoor = 1;
+
+  for (int64_t n = 0; n < N; ++n) {
+    float *flow_ptr_N = flow_data + n * flow_sN;
+    for (int64_t h = 0; h < out_H; ++h) {
+      for (int64_t w = 0; w < out_W; ++w) {
+        float *flow_ptr_NHW = flow_ptr_N + h * flow_sH + w * flow_sW;
+        float * flow_ptr_NHW_x = flow_ptr_NHW;
+        float * flow_ptr_NHW_y = &flow_ptr_NHW[flow_sCoor]; // flow_ptr_NHW + flow_sCoor;
+        *flow_ptr_NHW_x = 2.0 * (*flow_ptr_NHW_x + w) / MAX(out_W - 1, 1) - 1.0;
+        *flow_ptr_NHW_y = 2.0 *(*flow_ptr_NHW_y + h) / MAX(out_H - 1, 1) - 1.0;
+      }
+      // std::cout<<std::endl;
+    }
+  }
+  
+  
+  
+  const float * grid_data = flow_data;
+
+  // bilinear grid sample
+  float* out_ptr = output.data_ptr<float>();
+  const bool align_corners = true;
+  const int64_t padding_mode = 0;  // padding_mode: zeros
+  const int64_t interpolation_mode = 0; // interpolation_mode: bilinear
+  
+  int64_t grid_H = flow.size(1),grid_W = flow.size(2),grid_C = flow.size(3);
+  int64_t out_C = C;
+  int64_t inp_sN = C * inp_H * inp_W;//input_dims[1] * input_dims[2] * input_dims[3];
+  int64_t inp_sC = inp_H * inp_W;//input_dims[2] * input_dims[3];
+  int64_t inp_sH = inp_W;//input_dims[3];
+  int64_t inp_sW = 1;
+  int64_t grid_sN = grid_H * grid_W * grid_C;//grid_dims[1] * grid_dims[2] * grid_dims[3];
+  int64_t grid_sH = grid_W * grid_C;//grid_dims[2] * grid_dims[3];
+  int64_t grid_sW = grid_C;//grid_dims[3];
+  int64_t grid_sCoor = 1;
+  int64_t out_sN = out_C * out_H * out_W;//output_dims[1] * output_dims[2] * output_dims[3];
+  int64_t out_sC = out_H * out_W;//output_dims[2] * output_dims[3];
+  int64_t out_sH = out_W;//output_dims[3];
+  int64_t out_sW = 1;
+
+    // loop over each output pixel
+  for (int64_t n = 0; n < N; ++n) {
+    const float *grid_ptr_N = grid_data + n * grid_sN;
+    const float *inp_ptr_N = input_data + n * inp_sN;
+    for (int64_t h = 0; h < out_H; ++h) {
+      for (int64_t w = 0; w < out_W; ++w) {
+        const float *grid_ptr_NHW = grid_ptr_N + h * grid_sH + w * grid_sW;
+        float x = *grid_ptr_NHW;
+        float y = grid_ptr_NHW[grid_sCoor];
+
+        float ix = grid_sampler_compute_source_index(x, inp_W, padding_mode,
+                                                     align_corners);
+        float iy = grid_sampler_compute_source_index(y, inp_H, padding_mode,
+                                                     align_corners);
+
+        if (interpolation_mode == GridSamplerInterpolation::Bilinear) {
+          // get corner pixel values from (x, y)
+          // for 4d, we use north-east-south-west
+          int64_t ix_nw = static_cast<int64_t>(std::floor(ix));
+          int64_t iy_nw = static_cast<int64_t>(std::floor(iy));
+
+          int64_t ix_ne = ix_nw + 1;
+          int64_t iy_ne = iy_nw;
+
+          int64_t ix_sw = ix_nw;
+          int64_t iy_sw = iy_nw + 1;
+
+          int64_t ix_se = ix_nw + 1;
+          int64_t iy_se = iy_nw + 1;
+
+          // get surfaces to each neighbor:
+          float nw = (ix_se - ix) * (iy_se - iy);
+          float ne = (ix - ix_sw) * (iy_sw - iy);
+          float sw = (ix_ne - ix) * (iy - iy_ne);
+          float se = (ix - ix_nw) * (iy - iy_nw);
+
+          // calculate bilinear weighted pixel value and set output pixel
+          const float *inp_ptr_NC = inp_ptr_N;
+          float *out_ptr_NCHW = out_ptr + n * out_sN + h * out_sH + w * out_sW;
+          for (int64_t c = 0; c < C;
+               ++c, out_ptr_NCHW += out_sC, inp_ptr_NC += inp_sC) {
+            auto res = static_cast<float>(0);
+            if (within_bounds_2d(iy_nw, ix_nw, inp_H, inp_W)) {
+              res += inp_ptr_NC[iy_nw * inp_sH + ix_nw * inp_sW] * nw;
+            }
+            if (within_bounds_2d(iy_ne, ix_ne, inp_H, inp_W)) {
+              res += inp_ptr_NC[iy_ne * inp_sH + ix_ne * inp_sW] * ne;
+            }
+            if (within_bounds_2d(iy_sw, ix_sw, inp_H, inp_W)) {
+              res += inp_ptr_NC[iy_sw * inp_sH + ix_sw * inp_sW] * sw;
+            }
+            if (within_bounds_2d(iy_se, ix_se, inp_H, inp_W)) {
+              res += inp_ptr_NC[iy_se * inp_sH + ix_se * inp_sW] * se;
+            }
+            *out_ptr_NCHW = res;
+          }
+        } else if (interpolation_mode == GridSamplerInterpolation::Nearest) {
+          int64_t ix_nearest = static_cast<int64_t>(std::nearbyint(ix));
+          int64_t iy_nearest = static_cast<int64_t>(std::nearbyint(iy));
+
+          // assign nearest neighbor pixel value to output pixel
+          float *out_ptr_NCHW = out_ptr + n * out_sN + h * out_sH + w * out_sW;
+          const float *inp_ptr_NC = inp_ptr_N;
+          for (int64_t c = 0; c < C;
+               ++c, out_ptr_NCHW += out_sC, inp_ptr_NC += inp_sC) {
+            if (within_bounds_2d(iy_nearest, ix_nearest, inp_H, inp_W)) {
+              *out_ptr_NCHW =
+                  inp_ptr_NC[iy_nearest * inp_sH + ix_nearest * inp_sW];
+            } else {
+              *out_ptr_NCHW = static_cast<float>(0);
+            }
+          }
+        } else if (interpolation_mode == GridSamplerInterpolation::Bicubic) {
+          // grid_sampler_compute_source_index will "clip the value" of idx
+          // depends on the padding,
+          // which would cause calculation to be wrong,
+          // for example x = -0.1 -> ix = 0 for zero padding, but in bicubic ix
+          // = floor(x) = -1
+          // There would be more problem in reflection padding, since the -1 and
+          // +1 direction is not fixed in boundary condition
+          ix = grid_sampler_unnormalize(x, inp_W, align_corners);
+          iy = grid_sampler_unnormalize(y, inp_H, align_corners);
+
+          float ix_nw = std::floor(ix);
+          float iy_nw = std::floor(iy);
+
+          const float tx = ix - ix_nw;
+          const float ty = iy - iy_nw;
+
+          const float *inp_ptr_NC = inp_ptr_N;
+          float *out_ptr_NCHW = out_ptr + n * out_sN + h * out_sH + w * out_sW;
+          for (int64_t c = 0; c < C;
+               ++c, out_ptr_NCHW += out_sC, inp_ptr_NC += inp_sC) {
+            float coefficients[4];
+
+            // Interpolate 4 values in the x direction
+            for (int64_t i = 0; i < 4; ++i) {
+              coefficients[i] = cubic_interp1d<float>(
+                  get_value_bounded<float>(inp_ptr_NC, ix_nw - 1, iy_nw - 1 + i,
+                                           inp_W, inp_H, inp_sW, inp_sH,
+                                           padding_mode, align_corners),
+                  get_value_bounded<float>(inp_ptr_NC, ix_nw + 0, iy_nw - 1 + i,
+                                           inp_W, inp_H, inp_sW, inp_sH,
+                                           padding_mode, align_corners),
+                  get_value_bounded<float>(inp_ptr_NC, ix_nw + 1, iy_nw - 1 + i,
+                                           inp_W, inp_H, inp_sW, inp_sH,
+                                           padding_mode, align_corners),
+                  get_value_bounded<float>(inp_ptr_NC, ix_nw + 2, iy_nw - 1 + i,
+                                           inp_W, inp_H, inp_sW, inp_sH,
+                                           padding_mode, align_corners),
+                  tx);
+            }
+
+            // Interpolate in the y direction
+            *out_ptr_NCHW =
+                cubic_interp1d<float>(coefficients[0], coefficients[1],
+                                      coefficients[2], coefficients[3], ty);
+          }
+        }
+      }
+    }
+  }
+
+  return output;
+}
+static auto registry =
+  torch::RegisterOperators("custom_op_namespace::flow_warp", &flow_warp);
+
diff --git a/vsr_opt/flow_warp_pytorch_op/setup.py b/vsr_opt/flow_warp_pytorch_op/setup.py
new file mode 100644
index 0000000000..553fd277b2
--- /dev/null
+++ b/vsr_opt/flow_warp_pytorch_op/setup.py
@@ -0,0 +1,9 @@
+# SPDX-License-Identifier: Apache-2.0
+
+from setuptools import setup
+from torch.utils import cpp_extension
+
+setup(name='flow_warp',
+      ext_modules=[cpp_extension.CppExtension('flow_warp', ['flow_warp_op.cpp'])],
+      license='Apache License v2.0',
+      cmdclass={'build_ext': cpp_extension.BuildExtension})
diff --git a/vsr_opt/mmedit/__init__.py b/vsr_opt/mmedit/__init__.py
new file mode 100644
index 0000000000..05d4c20b70
--- /dev/null
+++ b/vsr_opt/mmedit/__init__.py
@@ -0,0 +1,34 @@
+# Copyright (c) OpenMMLab. All rights reserved.
+import mmcv
+
+from .version import __version__, version_info
+
+try:
+    from mmcv.utils import digit_version
+except ImportError:
+
+    def digit_version(version_str):
+        digit_ver = []
+        for x in version_str.split('.'):
+            if x.isdigit():
+                digit_ver.append(int(x))
+            elif x.find('rc') != -1:
+                patch_version = x.split('rc')
+                digit_ver.append(int(patch_version[0]) - 1)
+                digit_ver.append(int(patch_version[1]))
+        return digit_ver
+
+
+MMCV_MIN = '1.3.13'
+MMCV_MAX = '1.6'
+
+mmcv_min_version = digit_version(MMCV_MIN)
+mmcv_max_version = digit_version(MMCV_MAX)
+mmcv_version = digit_version(mmcv.__version__)
+
+
+assert (mmcv_min_version <= mmcv_version <= mmcv_max_version), \
+    f'mmcv=={mmcv.__version__} is used but incompatible. ' \
+    f'Please install mmcv-full>={mmcv_min_version}, <={mmcv_max_version}.'
+
+__all__ = ['__version__', 'version_info']
diff --git a/vsr_opt/mmedit/models/__init__.py b/vsr_opt/mmedit/models/__init__.py
new file mode 100644
index 0000000000..f35751e3fd
--- /dev/null
+++ b/vsr_opt/mmedit/models/__init__.py
@@ -0,0 +1,15 @@
+# Copyright (c) OpenMMLab. All rights reserved.
+from .backbones import *  # noqa: F401, F403
+from .base import BaseModel
+from .builder import (build, build_backbone, build_component, build_loss,
+                      build_model)
+from .common import *  # noqa: F401, F403
+from .losses import *  # noqa: F401, F403
+from .registry import BACKBONES, COMPONENTS, LOSSES, MODELS
+from .restorers import BasicRestorer
+
+__all__ = [
+    'BaseModel', 'BasicRestorer', 'build',
+    'build_backbone', 'build_component', 'build_loss', 'build_model',
+    'BACKBONES', 'COMPONENTS', 'LOSSES', 'MODELS'
+]
diff --git a/vsr_opt/mmedit/models/backbones/__init__.py b/vsr_opt/mmedit/models/backbones/__init__.py
new file mode 100644
index 0000000000..a41ec00f3a
--- /dev/null
+++ b/vsr_opt/mmedit/models/backbones/__init__.py
@@ -0,0 +1,6 @@
+# Copyright (c) OpenMMLab. All rights reserved.
+from .sr_backbones import (BasicVSRNet)
+
+__all__ = [
+    'BasicVSRNet'
+]
diff --git a/vsr_opt/mmedit/models/backbones/sr_backbones/__init__.py b/vsr_opt/mmedit/models/backbones/sr_backbones/__init__.py
new file mode 100644
index 0000000000..d2a8ce394d
--- /dev/null
+++ b/vsr_opt/mmedit/models/backbones/sr_backbones/__init__.py
@@ -0,0 +1,7 @@
+# Copyright (c) OpenMMLab. All rights reserved.
+from .basicvsr_net import BasicVSRNet
+
+
+__all__ = [
+    'BasicVSRNet',
+]
\ No newline at end of file
diff --git a/vsr_opt/mmedit/models/backbones/sr_backbones/basicvsr_net.py b/vsr_opt/mmedit/models/backbones/sr_backbones/basicvsr_net.py
new file mode 100644
index 0000000000..a1e1dcb6be
--- /dev/null
+++ b/vsr_opt/mmedit/models/backbones/sr_backbones/basicvsr_net.py
@@ -0,0 +1,432 @@
+# Copyright (c) OpenMMLab. All rights reserved.
+import torch
+import torch.nn as nn
+import torch.nn.functional as F
+from mmcv.cnn import ConvModule
+from mmcv.runner import load_checkpoint
+
+from mmedit.models.common import (PixelShufflePack, ResidualBlockNoBN,
+                                  flow_warp, make_layer)
+from mmedit.models.registry import BACKBONES
+# from mmedit.utils import get_root_logger
+
+
+@BACKBONES.register_module()
+class BasicVSRNet(nn.Module):
+    """BasicVSR network structure for video super-resolution.
+
+    Support only x4 upsampling.
+    Paper:
+        BasicVSR: The Search for Essential Components in Video Super-Resolution
+        and Beyond, CVPR, 2021
+
+    Args:
+        mid_channels (int): Channel number of the intermediate features.
+            Default: 64.
+        num_blocks (int): Number of residual blocks in each propagation branch.
+            Default: 30.
+        spynet_pretrained (str): Pre-trained model path of SPyNet.
+            Default: None.
+    """
+
+    def __init__(self, scale=4, mid_channels=64, num_blocks=30, spynet_pretrained=None, custom_op=False):
+
+        super().__init__()
+
+        self.scale = scale
+        self.mid_channels = mid_channels
+        self.custom_op = custom_op  # whether to use custom op
+
+        # optical flow network for feature alignment
+        self.spynet = SPyNet(pretrained=spynet_pretrained, custom_op=custom_op)
+
+        # propagation branches
+        self.backward_resblocks = ResidualBlocksWithInputConv(
+            mid_channels + 3, mid_channels, num_blocks)
+        self.forward_resblocks = ResidualBlocksWithInputConv(
+            mid_channels + 3, mid_channels, num_blocks)
+
+        # upsample
+        self.fusion = nn.Conv2d(
+            mid_channels * 2, mid_channels, 1, 1, 0, bias=True)
+        self.upsample1 = PixelShufflePack(
+            mid_channels, mid_channels, 2, upsample_kernel=3)
+        self.upsample2 = PixelShufflePack(
+            mid_channels, 64, 2, upsample_kernel=3)
+        self.conv_hr = nn.Conv2d(64, 64, 3, 1, 1)
+        self.conv_last = nn.Conv2d(64, 3, 3, 1, 1)
+        self.img_upsample = nn.Upsample(
+            scale_factor=scale, mode='bilinear', align_corners=False)
+
+        # activation function
+        self.lrelu = nn.LeakyReLU(negative_slope=0.1, inplace=True)
+
+    def check_if_mirror_extended(self, lrs):
+        """Check whether the input is a mirror-extended sequence.
+
+        If mirror-extended, the i-th (i=0, ..., t-1) frame is equal to the
+        (t-1-i)-th frame.
+
+        Args:
+            lrs (tensor): Input LR images with shape (n, t, c, h, w)
+        """
+
+        self.is_mirror_extended = False
+        if lrs.size(1) % 2 == 0:
+            lrs_1, lrs_2 = torch.chunk(lrs, 2, dim=1)
+            if torch.norm(lrs_1 - lrs_2.flip(1)) == 0:
+                self.is_mirror_extended = True
+
+    def compute_flow(self, lrs):
+        """Compute optical flow using SPyNet for feature warping.
+
+        Note that if the input is an mirror-extended sequence, 'flows_forward'
+        is not needed, since it is equal to 'flows_backward.flip(1)'.
+
+        Args:
+            lrs (tensor): Input LR images with shape (n, t, c, h, w)
+
+        Return:
+            tuple(Tensor): Optical flow. 'flows_forward' corresponds to the
+                flows used for forward-time propagation (current to previous).
+                'flows_backward' corresponds to the flows used for
+                backward-time propagation (current to next).
+        """
+
+        n, t, c, h, w = lrs.size()
+        lrs_1 = lrs[:, :-1, :, :, :].reshape(-1, c, h, w)
+        lrs_2 = lrs[:, 1:, :, :, :].reshape(-1, c, h, w)
+
+        flows_backward = self.spynet(lrs_1, lrs_2).view(n, t - 1, 2, h, w)
+
+        if self.is_mirror_extended:  # flows_forward = flows_backward.flip(1)
+            flows_forward = None
+        else:
+            flows_forward = self.spynet(lrs_2, lrs_1).view(n, t - 1, 2, h, w)
+
+        return flows_forward, flows_backward
+
+    def forward(self, lrs):
+        """Forward function for BasicVSR.
+
+        Args:
+            lrs (Tensor): Input LR sequence with shape (n, t, c, h, w).
+
+        Returns:
+            Tensor: Output HR sequence with shape (n, t, c, 4h, 4w).
+        """
+
+        n, t, c, h, w = lrs.size()
+        assert h >= 64 and w >= 64, (
+            'The height and width of inputs should be at least 64, '
+            f'but got {h} and {w}.')
+
+        # check whether the input is an extended sequence
+        self.check_if_mirror_extended(lrs)
+
+        # compute optical flow
+        flows_forward, flows_backward = self.compute_flow(lrs)
+
+        # backward-time propgation
+        outputs = []
+        feat_prop = lrs.new_zeros(n, self.mid_channels, h, w)
+        for i in range(t - 1, -1, -1):
+            if i < t - 1:  # no warping required for the last timestep
+                flow = flows_backward[:, i, :, :, :]
+                feat_prop = flow_warp(feat_prop, flow.permute(0, 2, 3, 1), custom_op=self.custom_op)
+
+            feat_prop = torch.cat([lrs[:, i, :, :, :], feat_prop], dim=1)
+            feat_prop = self.backward_resblocks(feat_prop)
+
+            outputs.append(feat_prop)
+        outputs = outputs[::-1]
+
+        # forward-time propagation and upsampling
+        feat_prop = torch.zeros_like(feat_prop)
+        for i in range(0, t):
+            lr_curr = lrs[:, i, :, :, :]
+            if i > 0:  # no warping required for the first timestep
+                if flows_forward is not None:
+                    flow = flows_forward[:, i - 1, :, :, :]
+                else:
+                    flow = flows_backward[:, -i, :, :, :]
+                feat_prop = flow_warp(feat_prop, flow.permute(0, 2, 3, 1), custom_op=self.custom_op)
+
+            feat_prop = torch.cat([lr_curr, feat_prop], dim=1)
+            feat_prop = self.forward_resblocks(feat_prop)
+
+            # upsampling given the backward and forward features
+            out = torch.cat([outputs[i], feat_prop], dim=1)
+            out = self.lrelu(self.fusion(out))
+            if self.scale == 4:
+                out = self.lrelu(self.upsample1(out))
+            out = self.lrelu(self.upsample2(out))
+            out = self.lrelu(self.conv_hr(out))
+            out = self.conv_last(out)
+            base = self.img_upsample(lr_curr)
+            out += base
+            outputs[i] = out
+
+        return torch.stack(outputs, dim=1)
+
+    def init_weights(self, pretrained=None, strict=True):
+        """Init weights for models.
+
+        Args:
+            pretrained (str, optional): Path for pretrained weights. If given
+                None, pretrained weights will not be loaded. Defaults: None.
+            strict (boo, optional): Whether strictly load the pretrained model.
+                Defaults to True.
+        """
+        # if isinstance(pretrained, str):
+        #     logger = get_root_logger()
+        #     load_checkpoint(self, pretrained, strict=strict, logger=logger)
+        # elif pretrained is not None:
+        #     raise TypeError(f'"pretrained" must be a str or None. '
+        #                     f'But received {type(pretrained)}.')
+
+
+class ResidualBlocksWithInputConv(nn.Module):
+    """Residual blocks with a convolution in front.
+
+    Args:
+        in_channels (int): Number of input channels of the first conv.
+        out_channels (int): Number of channels of the residual blocks.
+            Default: 64.
+        num_blocks (int): Number of residual blocks. Default: 30.
+    """
+
+    def __init__(self, in_channels, out_channels=64, num_blocks=30):
+        super().__init__()
+
+        main = []
+
+        # a convolution used to match the channels of the residual blocks
+        main.append(nn.Conv2d(in_channels, out_channels, 3, 1, 1, bias=True))
+        main.append(nn.LeakyReLU(negative_slope=0.1, inplace=True))
+
+        # residual blocks
+        main.append(
+            make_layer(
+                ResidualBlockNoBN, num_blocks, mid_channels=out_channels))
+
+        self.main = nn.Sequential(*main)
+
+    def forward(self, feat):
+        """
+        Forward function for ResidualBlocksWithInputConv.
+
+        Args:
+            feat (Tensor): Input feature with shape (n, in_channels, h, w)
+
+        Returns:
+            Tensor: Output feature with shape (n, out_channels, h, w)
+        """
+        return self.main(feat)
+
+
+class SPyNet(nn.Module):
+    """SPyNet network structure.
+
+    The difference to the SPyNet in [tof.py] is that
+        1. more SPyNetBasicModule is used in this version, and
+        2. no batch normalization is used in this version.
+
+    Paper:
+        Optical Flow Estimation using a Spatial Pyramid Network, CVPR, 2017
+
+    Args:
+        pretrained (str): path for pre-trained SPyNet. Default: None.
+    """
+
+    def __init__(self, pretrained, custom_op=False):
+        super().__init__()
+
+        self.basic_module = nn.ModuleList(
+            [SPyNetBasicModule() for _ in range(6)])
+        self.custom_op = custom_op
+
+        # if isinstance(pretrained, str):
+        #     logger = get_root_logger()
+        #     load_checkpoint(self, pretrained, strict=True, logger=logger)
+        # elif pretrained is not None:
+        #     raise TypeError('[pretrained] should be str or None, '
+        #                     f'but got {type(pretrained)}.')
+
+        self.register_buffer(
+            'mean',
+            torch.Tensor([0.485, 0.456, 0.406]).view(1, 3, 1, 1))
+        self.register_buffer(
+            'std',
+            torch.Tensor([0.229, 0.224, 0.225]).view(1, 3, 1, 1))
+
+    def compute_flow(self, ref, supp):
+        """Compute flow from ref to supp.
+
+        Note that in this function, the images are already resized to a
+        multiple of 32.
+
+        Args:
+            ref (Tensor): Reference image with shape of (n, 3, h, w).
+            supp (Tensor): Supporting image with shape of (n, 3, h, w).
+
+        Returns:
+            Tensor: Estimated optical flow: (n, 2, h, w).
+        """
+        n, _, h, w = ref.size()
+
+        # normalize the input images
+        ref = [(ref - self.mean) / self.std]
+        supp = [(supp - self.mean) / self.std]
+
+        # generate downsampled frames
+        for level in range(5):
+            ref.append(
+                F.avg_pool2d(
+                    input=ref[-1],
+                    kernel_size=2,
+                    stride=2,
+                    count_include_pad=False))
+            supp.append(
+                F.avg_pool2d(
+                    input=supp[-1],
+                    kernel_size=2,
+                    stride=2,
+                    count_include_pad=False))
+        ref = ref[::-1]
+        supp = supp[::-1]
+
+        # flow computation
+        flow = ref[0].new_zeros(n, 2, h // 32, w // 32)
+        for level in range(len(ref)):
+            if level == 0:
+                flow_up = flow
+            else:
+                flow_up = F.interpolate(
+                    input=flow,
+                    scale_factor=2,
+                    mode='bilinear',
+                    align_corners=True) * 2.0
+
+            # add the residue to the upsampled flow
+            flow = flow_up + self.basic_module[level](
+                torch.cat([
+                    ref[level],
+                    flow_warp(
+                        supp[level],
+                        flow_up.permute(0, 2, 3, 1),
+                        padding_mode='border',
+                        custom_op=self.custom_op), flow_up
+                ], 1))
+
+        return flow
+
+    def forward(self, ref, supp):
+        """Forward function of SPyNet.
+
+        This function computes the optical flow from ref to supp.
+
+        Args:
+            ref (Tensor): Reference image with shape of (n, 3, h, w).
+            supp (Tensor): Supporting image with shape of (n, 3, h, w).
+
+        Returns:
+            Tensor: Estimated optical flow: (n, 2, h, w).
+        """
+
+        # upsize to a multiple of 32
+        h, w = ref.shape[2:4]
+        w_up = w if (w % 32) == 0 else 32 * (w // 32 + 1)
+        h_up = h if (h % 32) == 0 else 32 * (h // 32 + 1)
+        ref = F.interpolate(
+            input=ref, size=(h_up, w_up), mode='bilinear', align_corners=False)
+        supp = F.interpolate(
+            input=supp,
+            size=(h_up, w_up),
+            mode='bilinear',
+            align_corners=False)
+
+        # compute flow, and resize back to the original resolution
+        flow = F.interpolate(
+            input=self.compute_flow(ref, supp),
+            size=(h, w),
+            mode='bilinear',
+            align_corners=False)
+
+        # adjust the flow values
+        if self.custom_op is False:
+            flow[:, 0, :, :] *= float(w) / float(w_up)
+            flow[:, 1, :, :] *= float(h) / float(h_up)
+        else:
+            w_scale = float(w) / float(w_up)
+            h_scale = float(h) / float(h_up)
+            flow_0 = flow[:, 0, :, :]*w_scale
+            flow_1 = flow[:, 1, :, :]*h_scale
+            flow = torch.stack((flow_0,flow_1),dim=1)
+
+        return flow
+
+
+class SPyNetBasicModule(nn.Module):
+    """Basic Module for SPyNet.
+
+    Paper:
+        Optical Flow Estimation using a Spatial Pyramid Network, CVPR, 2017
+    """
+
+    def __init__(self):
+        super().__init__()
+
+        self.basic_module = nn.Sequential(
+            ConvModule(
+                in_channels=8,
+                out_channels=32,
+                kernel_size=7,
+                stride=1,
+                padding=3,
+                norm_cfg=None,
+                act_cfg=dict(type='ReLU')),
+            ConvModule(
+                in_channels=32,
+                out_channels=64,
+                kernel_size=7,
+                stride=1,
+                padding=3,
+                norm_cfg=None,
+                act_cfg=dict(type='ReLU')),
+            ConvModule(
+                in_channels=64,
+                out_channels=32,
+                kernel_size=7,
+                stride=1,
+                padding=3,
+                norm_cfg=None,
+                act_cfg=dict(type='ReLU')),
+            ConvModule(
+                in_channels=32,
+                out_channels=16,
+                kernel_size=7,
+                stride=1,
+                padding=3,
+                norm_cfg=None,
+                act_cfg=dict(type='ReLU')),
+            ConvModule(
+                in_channels=16,
+                out_channels=2,
+                kernel_size=7,
+                stride=1,
+                padding=3,
+                norm_cfg=None,
+                act_cfg=None))
+
+    def forward(self, tensor_input):
+        """
+        Args:
+            tensor_input (Tensor): Input tensor with shape (b, 8, h, w).
+                8 channels contain:
+                [reference image (3), neighbor image (3), initial flow (2)].
+
+        Returns:
+            Tensor: Refined flow with shape (b, 2, h, w)
+        """
+        return self.basic_module(tensor_input)
diff --git a/vsr_opt/mmedit/models/base.py b/vsr_opt/mmedit/models/base.py
new file mode 100644
index 0000000000..02327e2832
--- /dev/null
+++ b/vsr_opt/mmedit/models/base.py
@@ -0,0 +1,105 @@
+# Copyright (c) OpenMMLab. All rights reserved.
+from abc import ABCMeta, abstractmethod
+from collections import OrderedDict
+
+import torch
+import torch.nn as nn
+
+
+class BaseModel(nn.Module, metaclass=ABCMeta):
+    """Base model.
+
+    All models should subclass it.
+    All subclass should overwrite:
+
+        ``init_weights``, supporting to initialize models.
+
+        ``forward_train``, supporting to forward when training.
+
+        ``forward_test``, supporting to forward when testing.
+
+        ``train_step``, supporting to train one step when training.
+    """
+
+    @abstractmethod
+    def init_weights(self):
+        """Abstract method for initializing weight.
+
+        All subclass should overwrite it.
+        """
+
+    @abstractmethod
+    def forward_train(self, imgs, labels):
+        """Abstract method for training forward.
+
+        All subclass should overwrite it.
+        """
+
+    @abstractmethod
+    def forward_test(self, imgs):
+        """Abstract method for testing forward.
+
+        All subclass should overwrite it.
+        """
+
+    def forward(self, imgs, labels, test_mode, **kwargs):
+        """Forward function for base model.
+
+        Args:
+            imgs (Tensor): Input image(s).
+            labels (Tensor): Ground-truth label(s).
+            test_mode (bool): Whether in test mode.
+            kwargs (dict): Other arguments.
+
+        Returns:
+            Tensor: Forward results.
+        """
+
+        if test_mode:
+            return self.forward_test(imgs, **kwargs)
+
+        return self.forward_train(imgs, labels, **kwargs)
+
+    @abstractmethod
+    def train_step(self, data_batch, optimizer):
+        """Abstract method for one training step.
+
+        All subclass should overwrite it.
+        """
+
+    def val_step(self, data_batch, **kwargs):
+        """Abstract method for one validation step.
+
+        All subclass should overwrite it.
+        """
+        output = self.forward_test(**data_batch, **kwargs)
+        return output
+
+    def parse_losses(self, losses):
+        """Parse losses dict for different loss variants.
+
+        Args:
+            losses (dict): Loss dict.
+
+        Returns:
+            loss (float): Sum of the total loss.
+            log_vars (dict): loss dict for different variants.
+        """
+        log_vars = OrderedDict()
+        for loss_name, loss_value in losses.items():
+            if isinstance(loss_value, torch.Tensor):
+                log_vars[loss_name] = loss_value.mean()
+            elif isinstance(loss_value, list):
+                log_vars[loss_name] = sum(_loss.mean() for _loss in loss_value)
+            else:
+                raise TypeError(
+                    f'{loss_name} is not a tensor or list of tensors')
+
+        loss = sum(_value for _key, _value in log_vars.items()
+                   if 'loss' in _key)
+
+        log_vars['loss'] = loss
+        for name in log_vars:
+            log_vars[name] = log_vars[name].item()
+
+        return loss, log_vars
diff --git a/vsr_opt/mmedit/models/builder.py b/vsr_opt/mmedit/models/builder.py
new file mode 100644
index 0000000000..8606225aa6
--- /dev/null
+++ b/vsr_opt/mmedit/models/builder.py
@@ -0,0 +1,60 @@
+# Copyright (c) OpenMMLab. All rights reserved.
+import torch.nn as nn
+from mmcv import build_from_cfg
+
+from .registry import BACKBONES, COMPONENTS, LOSSES, MODELS
+
+
+def build(cfg, registry, default_args=None):
+    """Build module function.
+
+    Args:
+        cfg (dict): Configuration for building modules.
+        registry (obj): ``registry`` object.
+        default_args (dict, optional): Default arguments. Defaults to None.
+    """
+    if isinstance(cfg, list):
+        modules = [
+            build_from_cfg(cfg_, registry, default_args) for cfg_ in cfg
+        ]
+        return nn.Sequential(*modules)
+
+    return build_from_cfg(cfg, registry, default_args)
+
+
+def build_backbone(cfg):
+    """Build backbone.
+
+    Args:
+        cfg (dict): Configuration for building backbone.
+    """
+    return build(cfg, BACKBONES)
+
+
+def build_component(cfg):
+    """Build component.
+
+    Args:
+        cfg (dict): Configuration for building component.
+    """
+    return build(cfg, COMPONENTS)
+
+
+def build_loss(cfg):
+    """Build loss.
+
+    Args:
+        cfg (dict): Configuration for building loss.
+    """
+    return build(cfg, LOSSES)
+
+
+def build_model(cfg, train_cfg=None, test_cfg=None):
+    """Build model.
+
+    Args:
+        cfg (dict): Configuration for building model.
+        train_cfg (dict): Training configuration. Default: None.
+        test_cfg (dict): Testing configuration. Default: None.
+    """
+    return build(cfg, MODELS, dict(train_cfg=train_cfg, test_cfg=test_cfg))
diff --git a/vsr_opt/mmedit/models/common/__init__.py b/vsr_opt/mmedit/models/common/__init__.py
new file mode 100644
index 0000000000..4b01e48d6e
--- /dev/null
+++ b/vsr_opt/mmedit/models/common/__init__.py
@@ -0,0 +1,10 @@
+# Copyright (c) OpenMMLab. All rights reserved.
+from .flow_warp import flow_warp
+from .sr_backbone_utils import (ResidualBlockNoBN, default_init_weights,
+                                make_layer)
+from .upsample import PixelShufflePack
+
+__all__ = [
+    'PixelShufflePack', 'default_init_weights',
+    'ResidualBlockNoBN', 'make_layer', 'flow_warp'
+]
diff --git a/vsr_opt/mmedit/models/common/flow_warp.py b/vsr_opt/mmedit/models/common/flow_warp.py
new file mode 100644
index 0000000000..9b20e30163
--- /dev/null
+++ b/vsr_opt/mmedit/models/common/flow_warp.py
@@ -0,0 +1,65 @@
+# Copyright (c) OpenMMLab. All rights reserved.
+import torch
+import torch.nn.functional as F
+from mmcv.ops.point_sample import bilinear_grid_sample
+
+
+def flow_warp(x,
+              flow,
+              interpolation='bilinear',
+              padding_mode='zeros',
+              align_corners=True,
+              custom_op=False):
+    """Warp an image or a feature map with optical flow.
+
+    Args:
+        x (Tensor): Tensor with size (n, c, h, w).
+        flow (Tensor): Tensor with size (n, h, w, 2). The last dimension is
+            a two-channel, denoting the width and height relative offsets.
+            Note that the values are not normalized to [-1, 1].
+        interpolation (str): Interpolation mode: 'nearest' or 'bilinear'.
+            Default: 'bilinear'.
+        padding_mode (str): Padding mode: 'zeros' or 'border' or 'reflection'.
+            Default: 'zeros'.
+        align_corners (bool): Whether align corners. Default: True.
+
+    Returns:
+        Tensor: Warped image or feature map.
+    """
+    if custom_op:
+        torch.ops.load_library(
+            "./flow_warp_pytorch_op/build/lib.linux-x86_64-cpython-39/flow_warp.cpython-39-x86_64-linux-gnu.so")
+        register_custom_op()
+        result = torch.ops.custom_op_namespace.flow_warp(x, flow)
+        return result
+
+    if x.size()[-2:] != flow.size()[1:3]:
+        raise ValueError(f'The spatial sizes of input ({x.size()[-2:]}) and '
+                         f'flow ({flow.size()[1:3]}) are not the same.')
+    _, _, h, w = x.size()
+    # create mesh grid
+    grid_y, grid_x = torch.meshgrid(torch.arange(0, h), torch.arange(0, w))
+    grid = torch.stack((grid_x, grid_y), 2).type_as(x)  # (h, w, 2)
+    grid.requires_grad = False
+
+    grid_flow = grid + flow
+    # scale grid_flow to [-1,1]
+    grid_flow_x = 2.0 * grid_flow[:, :, :, 0] / max(w - 1, 1) - 1.0
+    grid_flow_y = 2.0 * grid_flow[:, :, :, 1] / max(h - 1, 1) - 1.0
+    grid_flow = torch.stack((grid_flow_x, grid_flow_y), dim=3)
+    output = bilinear_grid_sample(x, grid_flow, align_corners=align_corners)
+    # output = F.grid_sample(
+    #     x,
+    #     grid_flow,
+    #     mode=interpolation,
+    #     padding_mode=padding_mode,
+    #     align_corners=align_corners)
+    return output
+
+
+def register_custom_op():
+    def my_flow_warp(g, input, flow):
+        return g.op("custom_op::flow_warp", input, flow)
+
+    from torch.onnx import register_custom_op_symbolic
+    register_custom_op_symbolic("custom_op_namespace::flow_warp", my_flow_warp, 11)
diff --git a/vsr_opt/mmedit/models/common/sr_backbone_utils.py b/vsr_opt/mmedit/models/common/sr_backbone_utils.py
new file mode 100644
index 0000000000..b4b0aad915
--- /dev/null
+++ b/vsr_opt/mmedit/models/common/sr_backbone_utils.py
@@ -0,0 +1,97 @@
+# Copyright (c) OpenMMLab. All rights reserved.
+import torch.nn as nn
+from mmcv.cnn import constant_init, kaiming_init
+from mmcv.utils.parrots_wrapper import _BatchNorm
+
+
+def default_init_weights(module, scale=1):
+    """Initialize network weights.
+
+    Args:
+        modules (nn.Module): Modules to be initialized.
+        scale (float): Scale initialized weights, especially for residual
+            blocks.
+    """
+    for m in module.modules():
+        if isinstance(m, nn.Conv2d):
+            kaiming_init(m, a=0, mode='fan_in', bias=0)
+            m.weight.data *= scale
+        elif isinstance(m, nn.Linear):
+            kaiming_init(m, a=0, mode='fan_in', bias=0)
+            m.weight.data *= scale
+        elif isinstance(m, _BatchNorm):
+            constant_init(m.weight, val=1, bias=0)
+
+
+def make_layer(block, num_blocks, **kwarg):
+    """Make layers by stacking the same blocks.
+
+    Args:
+        block (nn.module): nn.module class for basic block.
+        num_blocks (int): number of blocks.
+
+    Returns:
+        nn.Sequential: Stacked blocks in nn.Sequential.
+    """
+    layers = []
+    for _ in range(num_blocks):
+        layers.append(block(**kwarg))
+    return nn.Sequential(*layers)
+
+
+class ResidualBlockNoBN(nn.Module):
+    """Residual block without BN.
+
+    It has a style of:
+
+    ::
+
+        ---Conv-ReLU-Conv-+-
+         |________________|
+
+    Args:
+        mid_channels (int): Channel number of intermediate features.
+            Default: 64.
+        res_scale (float): Used to scale the residual before addition.
+            Default: 1.0.
+    """
+
+    def __init__(self, mid_channels=64, res_scale=1.0):
+        super().__init__()
+        self.res_scale = res_scale
+        self.conv1 = nn.Conv2d(mid_channels, mid_channels, 3, 1, 1, bias=True)
+        self.conv2 = nn.Conv2d(mid_channels, mid_channels, 3, 1, 1, bias=True)
+
+        self.relu = nn.ReLU(inplace=True)
+
+        # if res_scale < 1.0, use the default initialization, as in EDSR.
+        # if res_scale = 1.0, use scaled kaiming_init, as in MSRResNet.
+        if res_scale == 1.0:
+            self.init_weights()
+
+    def init_weights(self):
+        """Initialize weights for ResidualBlockNoBN.
+
+        Initialization methods like `kaiming_init` are for VGG-style
+        modules. For modules with residual paths, using smaller std is
+        better for stability and performance. We empirically use 0.1.
+        See more details in "ESRGAN: Enhanced Super-Resolution Generative
+        Adversarial Networks"
+        """
+
+        for m in [self.conv1, self.conv2]:
+            default_init_weights(m, 0.1)
+
+    def forward(self, x):
+        """Forward function.
+
+        Args:
+            x (Tensor): Input tensor with shape (n, c, h, w).
+
+        Returns:
+            Tensor: Forward results.
+        """
+
+        identity = x
+        out = self.conv2(self.relu(self.conv1(x)))
+        return identity + out * self.res_scale
diff --git a/vsr_opt/mmedit/models/common/upsample.py b/vsr_opt/mmedit/models/common/upsample.py
new file mode 100644
index 0000000000..f39ec1a9e4
--- /dev/null
+++ b/vsr_opt/mmedit/models/common/upsample.py
@@ -0,0 +1,51 @@
+# Copyright (c) OpenMMLab. All rights reserved.
+import torch.nn as nn
+import torch.nn.functional as F
+
+from .sr_backbone_utils import default_init_weights
+
+
+class PixelShufflePack(nn.Module):
+    """ Pixel Shuffle upsample layer.
+
+    Args:
+        in_channels (int): Number of input channels.
+        out_channels (int): Number of output channels.
+        scale_factor (int): Upsample ratio.
+        upsample_kernel (int): Kernel size of Conv layer to expand channels.
+
+    Returns:
+        Upsampled feature map.
+    """
+
+    def __init__(self, in_channels, out_channels, scale_factor,
+                 upsample_kernel):
+        super().__init__()
+        self.in_channels = in_channels
+        self.out_channels = out_channels
+        self.scale_factor = scale_factor
+        self.upsample_kernel = upsample_kernel
+        self.upsample_conv = nn.Conv2d(
+            self.in_channels,
+            self.out_channels * scale_factor * scale_factor,
+            self.upsample_kernel,
+            padding=(self.upsample_kernel - 1) // 2)
+        self.init_weights()
+
+    def init_weights(self):
+        """Initialize weights for PixelShufflePack.
+        """
+        default_init_weights(self, 1)
+
+    def forward(self, x):
+        """Forward function for PixelShufflePack.
+
+        Args:
+            x (Tensor): Input tensor with shape (n, c, h, w).
+
+        Returns:
+            Tensor: Forward results.
+        """
+        x = self.upsample_conv(x)
+        x = F.pixel_shuffle(x, self.scale_factor)
+        return x
diff --git a/vsr_opt/mmedit/models/losses/__init__.py b/vsr_opt/mmedit/models/losses/__init__.py
new file mode 100644
index 0000000000..7ea4d03db8
--- /dev/null
+++ b/vsr_opt/mmedit/models/losses/__init__.py
@@ -0,0 +1,5 @@
+from .pixelwise_loss import CharbonnierLoss
+
+__all__ = [
+    'CharbonnierLoss',
+]
diff --git a/vsr_opt/mmedit/models/losses/pixelwise_loss.py b/vsr_opt/mmedit/models/losses/pixelwise_loss.py
new file mode 100644
index 0000000000..2f2435b8d3
--- /dev/null
+++ b/vsr_opt/mmedit/models/losses/pixelwise_loss.py
@@ -0,0 +1,221 @@
+# Copyright (c) OpenMMLab. All rights reserved.
+import torch
+import torch.nn as nn
+import torch.nn.functional as F
+
+from ..registry import LOSSES
+from .utils import masked_loss
+
+_reduction_modes = ['none', 'mean', 'sum']
+
+
+@masked_loss
+def l1_loss(pred, target):
+    """L1 loss.
+
+    Args:
+        pred (Tensor): Prediction Tensor with shape (n, c, h, w).
+        target ([type]): Target Tensor with shape (n, c, h, w).
+
+    Returns:
+        Tensor: Calculated L1 loss.
+    """
+    return F.l1_loss(pred, target, reduction='none')
+
+
+@masked_loss
+def mse_loss(pred, target):
+    """MSE loss.
+
+    Args:
+        pred (Tensor): Prediction Tensor with shape (n, c, h, w).
+        target ([type]): Target Tensor with shape (n, c, h, w).
+
+    Returns:
+        Tensor: Calculated MSE loss.
+    """
+    return F.mse_loss(pred, target, reduction='none')
+
+
+@masked_loss
+def charbonnier_loss(pred, target, eps=1e-12):
+    """Charbonnier loss.
+
+    Args:
+        pred (Tensor): Prediction Tensor with shape (n, c, h, w).
+        target ([type]): Target Tensor with shape (n, c, h, w).
+
+    Returns:
+        Tensor: Calculated Charbonnier loss.
+    """
+    return torch.sqrt((pred - target)**2 + eps)
+
+
+@LOSSES.register_module()
+class L1Loss(nn.Module):
+    """L1 (mean absolute error, MAE) loss.
+
+    Args:
+        loss_weight (float): Loss weight for L1 loss. Default: 1.0.
+        reduction (str): Specifies the reduction to apply to the output.
+            Supported choices are 'none' | 'mean' | 'sum'. Default: 'mean'.
+        sample_wise (bool): Whether calculate the loss sample-wise. This
+            argument only takes effect when `reduction` is 'mean' and `weight`
+            (argument of `forward()`) is not None. It will first reduce loss
+            with 'mean' per-sample, and then it means over all the samples.
+            Default: False.
+    """
+
+    def __init__(self, loss_weight=1.0, reduction='mean', sample_wise=False):
+        super().__init__()
+        if reduction not in ['none', 'mean', 'sum']:
+            raise ValueError(f'Unsupported reduction mode: {reduction}. '
+                             f'Supported ones are: {_reduction_modes}')
+
+        self.loss_weight = loss_weight
+        self.reduction = reduction
+        self.sample_wise = sample_wise
+
+    def forward(self, pred, target, weight=None, **kwargs):
+        """Forward Function.
+
+        Args:
+            pred (Tensor): of shape (N, C, H, W). Predicted tensor.
+            target (Tensor): of shape (N, C, H, W). Ground truth tensor.
+            weight (Tensor, optional): of shape (N, C, H, W). Element-wise
+                weights. Default: None.
+        """
+        return self.loss_weight * l1_loss(
+            pred,
+            target,
+            weight,
+            reduction=self.reduction,
+            sample_wise=self.sample_wise)
+
+
+@LOSSES.register_module()
+class MSELoss(nn.Module):
+    """MSE (L2) loss.
+
+    Args:
+        loss_weight (float): Loss weight for MSE loss. Default: 1.0.
+        reduction (str): Specifies the reduction to apply to the output.
+            Supported choices are 'none' | 'mean' | 'sum'. Default: 'mean'.
+        sample_wise (bool): Whether calculate the loss sample-wise. This
+            argument only takes effect when `reduction` is 'mean' and `weight`
+            (argument of `forward()`) is not None. It will first reduces loss
+            with 'mean' per-sample, and then it means over all the samples.
+            Default: False.
+    """
+
+    def __init__(self, loss_weight=1.0, reduction='mean', sample_wise=False):
+        super().__init__()
+        if reduction not in ['none', 'mean', 'sum']:
+            raise ValueError(f'Unsupported reduction mode: {reduction}. '
+                             f'Supported ones are: {_reduction_modes}')
+
+        self.loss_weight = loss_weight
+        self.reduction = reduction
+        self.sample_wise = sample_wise
+
+    def forward(self, pred, target, weight=None, **kwargs):
+        """Forward Function.
+
+        Args:
+            pred (Tensor): of shape (N, C, H, W). Predicted tensor.
+            target (Tensor): of shape (N, C, H, W). Ground truth tensor.
+            weight (Tensor, optional): of shape (N, C, H, W). Element-wise
+                weights. Default: None.
+        """
+        return self.loss_weight * mse_loss(
+            pred,
+            target,
+            weight,
+            reduction=self.reduction,
+            sample_wise=self.sample_wise)
+
+
+@LOSSES.register_module()
+class CharbonnierLoss(nn.Module):
+    """Charbonnier loss (one variant of Robust L1Loss, a differentiable
+    variant of L1Loss).
+
+    Described in "Deep Laplacian Pyramid Networks for Fast and Accurate
+        Super-Resolution".
+
+    Args:
+        loss_weight (float): Loss weight for L1 loss. Default: 1.0.
+        reduction (str): Specifies the reduction to apply to the output.
+            Supported choices are 'none' | 'mean' | 'sum'. Default: 'mean'.
+        sample_wise (bool): Whether calculate the loss sample-wise. This
+            argument only takes effect when `reduction` is 'mean' and `weight`
+            (argument of `forward()`) is not None. It will first reduces loss
+            with 'mean' per-sample, and then it means over all the samples.
+            Default: False.
+        eps (float): A value used to control the curvature near zero.
+            Default: 1e-12.
+    """
+
+    def __init__(self,
+                 loss_weight=1.0,
+                 reduction='mean',
+                 sample_wise=False,
+                 eps=1e-12):
+        super().__init__()
+        if reduction not in ['none', 'mean', 'sum']:
+            raise ValueError(f'Unsupported reduction mode: {reduction}. '
+                             f'Supported ones are: {_reduction_modes}')
+
+        self.loss_weight = loss_weight
+        self.reduction = reduction
+        self.sample_wise = sample_wise
+        self.eps = eps
+
+    def forward(self, pred, target, weight=None, **kwargs):
+        """Forward Function.
+
+        Args:
+            pred (Tensor): of shape (N, C, H, W). Predicted tensor.
+            target (Tensor): of shape (N, C, H, W). Ground truth tensor.
+            weight (Tensor, optional): of shape (N, C, H, W). Element-wise
+                weights. Default: None.
+        """
+        return self.loss_weight * charbonnier_loss(
+            pred,
+            target,
+            weight,
+            eps=self.eps,
+            reduction=self.reduction,
+            sample_wise=self.sample_wise)
+
+
+@LOSSES.register_module()
+class MaskedTVLoss(L1Loss):
+    """Masked TV loss.
+
+        Args:
+            loss_weight (float, optional): Loss weight. Defaults to 1.0.
+    """
+
+    def __init__(self, loss_weight=1.0):
+        super().__init__(loss_weight=loss_weight)
+
+    def forward(self, pred, mask=None):
+        """Forward function.
+
+        Args:
+            pred (torch.Tensor): Tensor with shape of (n, c, h, w).
+            mask (torch.Tensor, optional): Tensor with shape of (n, 1, h, w).
+                Defaults to None.
+
+        Returns:
+            [type]: [description]
+        """
+        y_diff = super().forward(
+            pred[:, :, :-1, :], pred[:, :, 1:, :], weight=mask[:, :, :-1, :])
+        x_diff = super().forward(
+            pred[:, :, :, :-1], pred[:, :, :, 1:], weight=mask[:, :, :, :-1])
+
+        loss = x_diff + y_diff
+
+        return loss
diff --git a/vsr_opt/mmedit/models/losses/utils.py b/vsr_opt/mmedit/models/losses/utils.py
new file mode 100644
index 0000000000..2f536d9243
--- /dev/null
+++ b/vsr_opt/mmedit/models/losses/utils.py
@@ -0,0 +1,115 @@
+# Copyright (c) OpenMMLab. All rights reserved.
+import functools
+
+import torch.nn.functional as F
+
+
+def reduce_loss(loss, reduction):
+    """Reduce loss as specified.
+
+    Args:
+        loss (Tensor): Elementwise loss tensor.
+        reduction (str): Options are "none", "mean" and "sum".
+
+    Returns:
+        Tensor: Reduced loss tensor.
+    """
+    reduction_enum = F._Reduction.get_enum(reduction)
+    # none: 0, elementwise_mean:1, sum: 2
+    if reduction_enum == 0:
+        return loss
+    if reduction_enum == 1:
+        return loss.mean()
+
+    return loss.sum()
+
+
+def mask_reduce_loss(loss, weight=None, reduction='mean', sample_wise=False):
+    """Apply element-wise weight and reduce loss.
+
+    Args:
+        loss (Tensor): Element-wise loss.
+        weight (Tensor): Element-wise weights. Default: None.
+        reduction (str): Same as built-in losses of PyTorch. Options are
+            "none", "mean" and "sum". Default: 'mean'.
+        sample_wise (bool): Whether calculate the loss sample-wise. This
+            argument only takes effect when `reduction` is 'mean' and `weight`
+            (argument of `forward()`) is not None. It will first reduces loss
+            with 'mean' per-sample, and then it means over all the samples.
+            Default: False.
+
+    Returns:
+        Tensor: Processed loss values.
+    """
+    # if weight is specified, apply element-wise weight
+    if weight is not None:
+        assert weight.dim() == loss.dim()
+        assert weight.size(1) == 1 or weight.size(1) == loss.size(1)
+        loss = loss * weight
+
+    # if weight is not specified or reduction is sum, just reduce the loss
+    if weight is None or reduction == 'sum':
+        loss = reduce_loss(loss, reduction)
+    # if reduction is mean, then compute mean over masked region
+    elif reduction == 'mean':
+        # expand weight from N1HW to NCHW
+        if weight.size(1) == 1:
+            weight = weight.expand_as(loss)
+        # small value to prevent division by zero
+        eps = 1e-12
+
+        # perform sample-wise mean
+        if sample_wise:
+            weight = weight.sum(dim=[1, 2, 3], keepdim=True)  # NCHW to N111
+            loss = (loss / (weight + eps)).sum() / weight.size(0)
+        # perform pixel-wise mean
+        else:
+            loss = loss.sum() / (weight.sum() + eps)
+
+    return loss
+
+
+def masked_loss(loss_func):
+    """Create a masked version of a given loss function.
+
+    To use this decorator, the loss function must have the signature like
+    `loss_func(pred, target, **kwargs)`. The function only needs to compute
+    element-wise loss without any reduction. This decorator will add weight
+    and reduction arguments to the function. The decorated function will have
+    the signature like `loss_func(pred, target, weight=None, reduction='mean',
+    avg_factor=None, **kwargs)`.
+
+    :Example:
+
+    >>> import torch
+    >>> @masked_loss
+    >>> def l1_loss(pred, target):
+    >>>     return (pred - target).abs()
+
+    >>> pred = torch.Tensor([0, 2, 3])
+    >>> target = torch.Tensor([1, 1, 1])
+    >>> weight = torch.Tensor([1, 0, 1])
+
+    >>> l1_loss(pred, target)
+    tensor(1.3333)
+    >>> l1_loss(pred, target, weight)
+    tensor(1.5000)
+    >>> l1_loss(pred, target, reduction='none')
+    tensor([1., 1., 2.])
+    >>> l1_loss(pred, target, weight, reduction='sum')
+    tensor(3.)
+    """
+
+    @functools.wraps(loss_func)
+    def wrapper(pred,
+                target,
+                weight=None,
+                reduction='mean',
+                sample_wise=False,
+                **kwargs):
+        # get element-wise loss
+        loss = loss_func(pred, target, **kwargs)
+        loss = mask_reduce_loss(loss, weight, reduction, sample_wise)
+        return loss
+
+    return wrapper
diff --git a/vsr_opt/mmedit/models/registry.py b/vsr_opt/mmedit/models/registry.py
new file mode 100644
index 0000000000..0a574b6678
--- /dev/null
+++ b/vsr_opt/mmedit/models/registry.py
@@ -0,0 +1,8 @@
+# Copyright (c) OpenMMLab. All rights reserved.
+from mmcv.cnn import MODELS as MMCV_MODELS
+from mmcv.utils import Registry
+
+MODELS = Registry('model', parent=MMCV_MODELS)
+BACKBONES = MODELS
+COMPONENTS = MODELS
+LOSSES = MODELS
diff --git a/vsr_opt/mmedit/models/restorers/__init__.py b/vsr_opt/mmedit/models/restorers/__init__.py
new file mode 100644
index 0000000000..a5a60b0950
--- /dev/null
+++ b/vsr_opt/mmedit/models/restorers/__init__.py
@@ -0,0 +1,7 @@
+# Copyright (c) OpenMMLab. All rights reserved.
+from .basic_restorer import BasicRestorer
+from .basicvsr import BasicVSR
+
+__all__ = [
+    'BasicRestorer', 'BasicVSR',
+]
diff --git a/vsr_opt/mmedit/models/restorers/basic_restorer.py b/vsr_opt/mmedit/models/restorers/basic_restorer.py
new file mode 100644
index 0000000000..e8c15ed664
--- /dev/null
+++ b/vsr_opt/mmedit/models/restorers/basic_restorer.py
@@ -0,0 +1,211 @@
+# Copyright (c) OpenMMLab. All rights reserved.
+import numbers
+import os.path as osp
+
+import mmcv
+from mmcv.runner import auto_fp16
+
+# from mmedit.core import psnr, ssim, tensor2img
+from ..base import BaseModel
+from ..builder import build_backbone, build_loss
+from ..registry import MODELS
+
+
+@MODELS.register_module()
+class BasicRestorer(BaseModel):
+    """Basic model for image restoration.
+
+    It must contain a generator that takes an image as inputs and outputs a
+    restored image. It also has a pixel-wise loss for training.
+
+    The subclasses should overwrite the function `forward_train`,
+    `forward_test` and `train_step`.
+
+    Args:
+        generator (dict): Config for the generator structure.
+        pixel_loss (dict): Config for pixel-wise loss.
+        train_cfg (dict): Config for training. Default: None.
+        test_cfg (dict): Config for testing. Default: None.
+        pretrained (str): Path for pretrained model. Default: None.
+    """
+    # allowed_metrics = {'PSNR': psnr, 'SSIM': ssim}
+    allowed_metrics = {}
+
+    def __init__(self,
+                 generator,
+                 pixel_loss,
+                 train_cfg=None,
+                 test_cfg=None,
+                 pretrained=None):
+        super().__init__()
+
+        self.train_cfg = train_cfg
+        self.test_cfg = test_cfg
+
+        # support fp16
+        self.fp16_enabled = False
+
+        # generator
+        self.generator = build_backbone(generator)
+        self.init_weights(pretrained)
+
+        # loss
+        self.pixel_loss = build_loss(pixel_loss)
+
+    def init_weights(self, pretrained=None):
+        """Init weights for models.
+
+        Args:
+            pretrained (str, optional): Path for pretrained weights. If given
+                None, pretrained weights will not be loaded. Defaults to None.
+        """
+        self.generator.init_weights(pretrained)
+
+    @auto_fp16(apply_to=('lq', ))
+    def forward(self, lq, gt=None, test_mode=False, **kwargs):
+        """Forward function.
+
+        Args:
+            lq (Tensor): Input lq images.
+            gt (Tensor): Ground-truth image. Default: None.
+            test_mode (bool): Whether in test mode or not. Default: False.
+            kwargs (dict): Other arguments.
+        """
+
+        if test_mode:
+            return self.forward_test(lq, gt, **kwargs)
+
+        return self.forward_train(lq, gt)
+
+    def forward_train(self, lq, gt):
+        """Training forward function.
+
+        Args:
+            lq (Tensor): LQ Tensor with shape (n, c, h, w).
+            gt (Tensor): GT Tensor with shape (n, c, h, w).
+
+        Returns:
+            Tensor: Output tensor.
+        """
+        losses = dict()
+        output = self.generator(lq)
+        loss_pix = self.pixel_loss(output, gt)
+        losses['loss_pix'] = loss_pix
+        outputs = dict(
+            losses=losses,
+            num_samples=len(gt.data),
+            results=dict(lq=lq.cpu(), gt=gt.cpu(), output=output.cpu()))
+        return outputs
+
+    def evaluate(self, output, gt):
+        """Evaluation function.
+
+        Args:
+            output (Tensor): Model output with shape (n, c, h, w).
+            gt (Tensor): GT Tensor with shape (n, c, h, w).
+
+        Returns:
+            dict: Evaluation results.
+        """
+        crop_border = self.test_cfg.crop_border
+
+        # output = tensor2img(output)
+        # gt = tensor2img(gt)
+
+        eval_result = dict()
+        for metric in self.test_cfg.metrics:
+            eval_result[metric] = self.allowed_metrics[metric](output, gt,
+                                                               crop_border)
+        return eval_result
+
+    def forward_test(self,
+                     lq,
+                     gt=None,
+                     meta=None,
+                     save_image=False,
+                     save_path=None,
+                     iteration=None):
+        """Testing forward function.
+
+        Args:
+            lq (Tensor): LQ Tensor with shape (n, c, h, w).
+            gt (Tensor): GT Tensor with shape (n, c, h, w). Default: None.
+            save_image (bool): Whether to save image. Default: False.
+            save_path (str): Path to save image. Default: None.
+            iteration (int): Iteration for the saving image name.
+                Default: None.
+
+        Returns:
+            dict: Output results.
+        """
+        output = self.generator(lq)
+        if self.test_cfg is not None and self.test_cfg.get('metrics', None):
+            assert gt is not None, (
+                'evaluation with metrics must have gt images.')
+            results = dict(eval_result=self.evaluate(output, gt))
+        else:
+            results = dict(lq=lq.cpu(), output=output.cpu())
+            if gt is not None:
+                results['gt'] = gt.cpu()
+
+        # # save image
+        # if save_image:
+        #     lq_path = meta[0]['lq_path']
+        #     folder_name = osp.splitext(osp.basename(lq_path))[0]
+        #     if isinstance(iteration, numbers.Number):
+        #         save_path = osp.join(save_path, folder_name,
+        #                              f'{folder_name}-{iteration + 1:06d}.png')
+        #     elif iteration is None:
+        #         save_path = osp.join(save_path, f'{folder_name}.png')
+        #     else:
+        #         raise ValueError('iteration should be number or None, '
+        #                          f'but got {type(iteration)}')
+        #     mmcv.imwrite(tensor2img(output), save_path)
+
+        return results
+
+    def forward_dummy(self, img):
+        """Used for computing network FLOPs.
+
+        Args:
+            img (Tensor): Input image.
+
+        Returns:
+            Tensor: Output image.
+        """
+        out = self.generator(img)
+        return out
+
+    def train_step(self, data_batch, optimizer):
+        """Train step.
+
+        Args:
+            data_batch (dict): A batch of data.
+            optimizer (obj): Optimizer.
+
+        Returns:
+            dict: Returned output.
+        """
+        outputs = self(**data_batch, test_mode=False)
+        loss, log_vars = self.parse_losses(outputs.pop('losses'))
+
+        # optimize
+        optimizer['generator'].zero_grad()
+        loss.backward()
+        optimizer['generator'].step()
+
+        outputs.update({'log_vars': log_vars})
+        return outputs
+
+    def val_step(self, data_batch, **kwargs):
+        """Validation step.
+
+        Args:
+            data_batch (dict): A batch of data.
+            kwargs (dict): Other arguments for ``val_step``.
+
+        Returns:
+            dict: Returned output.
+        """
+        output = self.forward_test(**data_batch, **kwargs)
+        return output
diff --git a/vsr_opt/mmedit/models/restorers/basicvsr.py b/vsr_opt/mmedit/models/restorers/basicvsr.py
new file mode 100644
index 0000000000..473a9e0038
--- /dev/null
+++ b/vsr_opt/mmedit/models/restorers/basicvsr.py
@@ -0,0 +1,224 @@
+# Copyright (c) OpenMMLab. All rights reserved.
+import numbers
+import os.path as osp
+
+import mmcv
+import numpy as np
+import torch
+
+# from mmedit.core import tensor2img
+from ..registry import MODELS
+from .basic_restorer import BasicRestorer
+
+
+@MODELS.register_module()
+class BasicVSR(BasicRestorer):
+    """BasicVSR model for video super-resolution.
+
+    Note that this model is used for IconVSR.
+
+    Paper:
+        BasicVSR: The Search for Essential Components in Video Super-Resolution
+        and Beyond, CVPR, 2021
+
+    Args:
+        generator (dict): Config for the generator structure.
+        pixel_loss (dict): Config for pixel-wise loss.
+        ensemble (dict): Config for ensemble. Default: None.
+        train_cfg (dict): Config for training. Default: None.
+        test_cfg (dict): Config for testing. Default: None.
+        pretrained (str): Path for pretrained model. Default: None.
+    """
+
+    def __init__(self,
+                 generator,
+                 pixel_loss,
+                 ensemble=None,
+                 train_cfg=None,
+                 test_cfg=None,
+                 pretrained=None):
+        super().__init__(generator, pixel_loss, train_cfg, test_cfg,
+                         pretrained)
+
+        # fix pre-trained networks
+        self.fix_iter = train_cfg.get('fix_iter', 0) if train_cfg else 0
+        self.is_weight_fixed = False
+
+        # count training steps
+        self.register_buffer('step_counter', torch.zeros(1))
+
+        # # ensemble
+        # self.forward_ensemble = None
+        # if ensemble is not None:
+        #     if ensemble['type'] == 'SpatialTemporalEnsemble':
+        #         from mmedit.models.common.ensemble import \
+        #             SpatialTemporalEnsemble
+        #         is_temporal = ensemble.get('is_temporal_ensemble', False)
+        #         self.forward_ensemble = SpatialTemporalEnsemble(is_temporal)
+        #     else:
+        #         raise NotImplementedError(
+        #             'Currently support only '
+        #             '"SpatialTemporalEnsemble", but got type '
+        #             f'[{ensemble["type"]}]')
+
+    def check_if_mirror_extended(self, lrs):
+        """Check whether the input is a mirror-extended sequence.
+
+        If mirror-extended, the i-th (i=0, ..., t-1) frame is equal to the
+        (t-1-i)-th frame.
+
+        Args:
+            lrs (tensor): Input LR images with shape (n, t, c, h, w)
+        """
+
+        is_mirror_extended = False
+        if lrs.size(1) % 2 == 0:
+            lrs_1, lrs_2 = torch.chunk(lrs, 2, dim=1)
+            if torch.norm(lrs_1 - lrs_2.flip(1)) == 0:
+                is_mirror_extended = True
+
+        return is_mirror_extended
+
+    def train_step(self, data_batch, optimizer):
+        """Train step.
+
+        Args:
+            data_batch (dict): A batch of data.
+            optimizer (obj): Optimizer.
+
+        Returns:
+            dict: Returned output.
+        """
+        # fix SPyNet and EDVR at the beginning
+        if self.step_counter < self.fix_iter:
+            if not self.is_weight_fixed:
+                self.is_weight_fixed = True
+                for k, v in self.generator.named_parameters():
+                    if 'spynet' in k or 'edvr' in k:
+                        v.requires_grad_(False)
+        elif self.step_counter == self.fix_iter:
+            # train all the parameters
+            self.generator.requires_grad_(True)
+
+        outputs = self(**data_batch, test_mode=False)
+        loss, log_vars = self.parse_losses(outputs.pop('losses'))
+
+        # optimize
+        optimizer['generator'].zero_grad()
+        loss.backward()
+        optimizer['generator'].step()
+
+        self.step_counter += 1
+
+        outputs.update({'log_vars': log_vars})
+        return outputs
+
+    def evaluate(self, output, gt):
+        """Evaluation function.
+
+        If the output contains multiple frames, we compute the metric
+        one by one and take an average.
+
+        Args:
+            output (Tensor): Model output with shape (n, t, c, h, w).
+            gt (Tensor): GT Tensor with shape (n, t, c, h, w).
+
+        Returns:
+            dict: Evaluation results.
+        """
+        crop_border = self.test_cfg.crop_border
+        convert_to = self.test_cfg.get('convert_to', None)
+
+        eval_result = dict()
+        # for metric in self.test_cfg.metrics:
+        #     if output.ndim == 5:  # a sequence: (n, t, c, h, w)
+        #         avg = []
+        #         for i in range(0, output.size(1)):
+        #             output_i = tensor2img(output[:, i, :, :, :])
+        #             gt_i = tensor2img(gt[:, i, :, :, :])
+        #             avg.append(self.allowed_metrics[metric](
+        #                 output_i, gt_i, crop_border, convert_to=convert_to))
+        #         eval_result[metric] = np.mean(avg)
+        #     elif output.ndim == 4:  # an image: (n, c, t, w), for Vimeo-90K-T
+        #         output_img = tensor2img(output)
+        #         gt_img = tensor2img(gt)
+        #         value = self.allowed_metrics[metric](
+        #             output_img, gt_img, crop_border, convert_to=convert_to)
+        #         eval_result[metric] = value
+
+        return eval_result
+
+    def forward_test(self,
+                     lq,
+                     gt=None,
+                     meta=None,
+                     save_image=False,
+                     save_path=None,
+                     iteration=None):
+        """Testing forward function.
+
+        Args:
+            lq (Tensor): LQ Tensor with shape (n, t, c, h, w).
+            gt (Tensor): GT Tensor with shape (n, t, c, h, w). Default: None.
+            save_image (bool): Whether to save image. Default: False.
+            save_path (str): Path to save image. Default: None.
+            iteration (int): Iteration for the saving image name.
+                Default: None.
+
+        Returns:
+            dict: Output results.
+        """
+        with torch.no_grad():
+            if self.forward_ensemble is not None:
+                output = self.forward_ensemble(lq, self.generator)
+            else:
+                output = self.generator(lq)
+
+        # If the GT is an image (i.e. the center frame), the output sequence is
+        # turned to an image.
+        if gt is not None and gt.ndim == 4:
+            t = output.size(1)
+            if self.check_if_mirror_extended(lq):  # with mirror extension
+                output = 0.5 * (output[:, t // 4] + output[:, -1 - t // 4])
+            else:  # without mirror extension
+                output = output[:, t // 2]
+
+        if self.test_cfg is not None and self.test_cfg.get('metrics', None):
+            assert gt is not None, (
+                'evaluation with metrics must have gt images.')
+            results = dict(eval_result=self.evaluate(output, gt))
+        else:
+            results = dict(lq=lq.cpu(), output=output.cpu())
+            if gt is not None:
+                results['gt'] = gt.cpu()
+
+        # # save image
+        # if save_image:
+        #     if output.ndim == 4:  # an image, key = 000001/0000 (Vimeo-90K)
+        #         img_name = meta[0]['key'].replace('/', '_')
+        #         if isinstance(iteration, numbers.Number):
+        #             save_path = osp.join(
+        #                 save_path, f'{img_name}-{iteration + 1:06d}.png')
+        #         elif iteration is None:
+        #             save_path = osp.join(save_path, f'{img_name}.png')
+        #         else:
+        #             raise ValueError('iteration should be number or None, '
+        #                              f'but got {type(iteration)}')
+        #         mmcv.imwrite(tensor2img(output), save_path)
+        #     elif output.ndim == 5:  # a sequence, key = 000
+        #         folder_name = meta[0]['key'].split('/')[0]
+        #         for i in range(0, output.size(1)):
+        #             if isinstance(iteration, numbers.Number):
+        #                 save_path_i = osp.join(
+        #                     save_path, folder_name,
+        #                     f'{i:08d}-{iteration + 1:06d}.png')
+        #             elif iteration is None:
+        #                 save_path_i = osp.join(save_path, folder_name,
+        #                                        f'{i:08d}.png')
+        #             else:
+        #                 raise ValueError('iteration should be number or None, '
+        #                                  f'but got {type(iteration)}')
+        #             mmcv.imwrite(
+        #                 tensor2img(output[:, i, :, :, :]), save_path_i)
+
+        return results
diff --git a/vsr_opt/mmedit/version.py b/vsr_opt/mmedit/version.py
new file mode 100644
index 0000000000..e397b0bc50
--- /dev/null
+++ b/vsr_opt/mmedit/version.py
@@ -0,0 +1,18 @@
+# Copyright (c) Open-MMLab. All rights reserved.
+
+__version__ = '0.14.0'
+
+
+def parse_version_info(version_str):
+    ver_info = []
+    for x in version_str.split('.'):
+        if x.isdigit():
+            ver_info.append(int(x))
+        elif x.find('rc') != -1:
+            patch_version = x.split('rc')
+            ver_info.append(int(patch_version[0]))
+            ver_info.append(f'rc{patch_version[1]}')
+    return tuple(ver_info)
+
+
+version_info = parse_version_info(__version__)
diff --git a/vsr_opt/tools/pytorch2onnx.py b/vsr_opt/tools/pytorch2onnx.py
index 7ebce5d70c..8bfcbc9eba 100644
--- a/vsr_opt/tools/pytorch2onnx.py
+++ b/vsr_opt/tools/pytorch2onnx.py
@@ -1,5 +1,11 @@
 import torch
 import argparse
+import os
+from mmedit.models import build_model
+import mmcv
+from mmcv.runner import load_checkpoint
+from mmcv.onnx import register_extra_symbolics
+
 
 def parse_args():
     parser = argparse.ArgumentParser(description='Pytorch model to ONNX model')
@@ -13,34 +19,94 @@ def parse_args():
         default='./',
         type=str,
         help='Path to store ONNX model file')
+    parser.add_argument('--custom_op', action='store_true', help='Whether to use custom op')
     args = parser.parse_args()
     return args
 
-def main(args):
-    model = torch.load(args.input_model,map_location=torch.device('cpu'))
-    model_name = args.input_model.split('/')[-1].split('.')[0]
-    output_model = args.output_dir + '.onnx'
-    import pdb;pdb.set_trace()
+
+def pytorch2onnx(model,
+                 input_shape=[1, 3, 3, 1080, 1920],
+                 opset_version=12,
+                 show=False,
+                 output_file='tmp.onnx',
+                 dynamic_export=False):
+    """Export Pytorch model to ONNX model and verify the outputs are same
+    between Pytorch and ONNX.
+
+    Args:
+        model (nn.Module): Pytorch model we want to export.
+        input (dict): We need to use this input to execute the model.
+        opset_version (int): The onnx op version. Default: 11.
+        show (bool): Whether print the computation graph. Default: False.
+        output_file (string): The path to where we store the output ONNX model.
+            Default: `tmp.onnx`.
+        verify (bool): Whether compare the outputs between Pytorch and ONNX.
+            Default: False.
+    """
     model.cpu().eval()
-    data = torch.randn([1,3,3,1080,1920])
-    script_model = torch.jit.trace(model,data)
-    freeze_model = torch.jit.freeze(script_model,preserved_attrs=["training"])
+
+    data = torch.randn(input_shape)
+    model.forward = model.forward_dummy
+    register_extra_symbolics(opset_version)
+    dynamic_axes = None
+    if dynamic_export:
+        dynamic_axes = {
+            'input': {
+                0: 'batch',
+                2: 'height',
+                3: 'width'
+            },
+            'output': {
+                0: 'batch',
+                2: 'height',
+                3: 'width'
+            }
+        }
+
+    script_model = torch.jit.trace(model, data)
+    freeze_model = torch.jit.freeze(script_model, preserved_attrs=["training"])
     with torch.no_grad():
         torch.onnx.export(
             freeze_model,
             data,
-            os.path.join(args.output_dir,output_model),
+            output_file,
             input_names=['input'],
             output_names=['output'],
             export_params=True,
             keep_initializers_as_inputs=False,
             verbose=show,
-            # training = TrainingMode.EVAL,  # @longkun
-            opset_version=12,
+            opset_version=opset_version,
             dynamic_axes=dynamic_axes,
-            do_constant_folding=True)
+            do_constant_folding=True
+        )
     print(f'Successfully exported ONNX model: {output_file}')
 
+
+def main(args):
+    model_name = args.input_model.split('/')[-1].split('.')[0]
+    suffix = ''
+    if args.custom_op is True:
+        suffix = '_custom_op'
+    output_model_path = os.path.join(args.output_dir, f'{model_name}{suffix}.onnx')
+
+    # build the model
+    config = mmcv.Config.fromfile('./configs/basicvsr_x2_cuc.py')
+    config.model.pretrained = None
+    config.model.generator.custom_op = args.custom_op
+    model = build_model(config.model, test_cfg=config.test_cfg)
+    checkpoint = load_checkpoint(model, args.input_model, map_location='cpu')
+    nif = 3
+    channel_num = 3
+    width = 1920
+    height = 1080
+    input_shape = [1, nif, channel_num, height, width]
+    # convert model to onnx file
+    pytorch2onnx(
+        model,
+        input_shape,
+        output_file=output_model_path)
+
+
 if __name__ == '__main__':
     args = parse_args()
-    main(args)
\ No newline at end of file
+    main(args)
-- 
2.25.1

