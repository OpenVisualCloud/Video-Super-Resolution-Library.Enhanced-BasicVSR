From 2990f5107f2e531d3ac1a927f6d3551529868958 Mon Sep 17 00:00:00 2001
From: Xiaoxia Liang <xiaoxia.liang@intel.com>
Date: Fri, 26 Jul 2024 18:57:53 +0000
Subject: [PATCH] dnn_ivsr_backend: process non-8 aligned resolution to make
 the video processing model can run at any resoultion.

Padding DNN data buffer to 8 aligned and then do video processing and
then crop to resolution same as input.

Signed-off-by: Xiaoxia Liang <xiaoxia.liang@intel.com>
---
 libavfilter/dnn/dnn_backend_ivsr.c | 52 +++++++++++++++++++++++++++++-
 libavfilter/dnn/dnn_io_proc.c      |  8 ++---
 libavfilter/vf_dnn_processing.c    | 20 ++++++------
 3 files changed, 65 insertions(+), 15 deletions(-)

diff --git a/libavfilter/dnn/dnn_backend_ivsr.c b/libavfilter/dnn/dnn_backend_ivsr.c
index 189705d309..6f2f5f0f07 100644
--- a/libavfilter/dnn/dnn_backend_ivsr.c
+++ b/libavfilter/dnn/dnn_backend_ivsr.c
@@ -57,6 +57,10 @@ typedef struct IVSROptions {
 typedef struct IVSRContext {
     const AVClass *class;
     IVSROptions options;
+    uint32_t frame_input_height;
+    uint32_t frame_input_width;
+    uint32_t model_input_height;
+    uint32_t model_input_width;
 } IVSRContext;
 
 typedef enum {
@@ -105,6 +109,8 @@ static const AVOption dnn_ivsr_options[] = {
 
 AVFILTER_DEFINE_CLASS(dnn_ivsr);
 
+#define ALIGNED_SIZE 8
+
 static int get_datatype_size(DNNDataType dt)
 {
     switch (dt) {
@@ -169,6 +175,20 @@ static void convert_nhwc_to_nchw(void* data, int N, int C, int H, int W) {
     av_free(temp);
 }
 
+/**
+ * set value for padding right and bottom.
+ */
+static void set_padding_value(void* data, uint32_t width, uint32_t height, uint32_t padding_width, uint32_t padding_height, int padding_value) {
+    int n_width = width + padding_width;
+    for (int h = 0; h < height; ++h) {
+        int index = h * (n_width) + width;
+        memset(data + index, padding_value, padding_width);
+    }
+
+    int index = height * n_width;
+    memset(data + index, padding_value, padding_height * n_width);
+}
+
 /* returns
  *     DNN_GENERIC_ERROR,
  *     DNN_MORE_FRAMES - waiting for more input frames,
@@ -187,6 +207,7 @@ static int fill_model_input_ivsr(IVSRModel * ivsr_model,
     void *in_data = NULL;
     int dims[5] = { 0, 0, 0, 0, 0 };
     float normalize_factor = ctx->options.normalize_factor;
+    int padding_height = 0, padding_width = 0;
 
     status = ivsr_get_attr(ivsr_model->handle, INPUT_TENSOR_DESC, dims);
     if (status != OK) {
@@ -227,7 +248,11 @@ static int fill_model_input_ivsr(IVSRModel * ivsr_model,
     input.scale = 0;
     input.mean = 0;
     input.layout = DL_NONE;
+    ctx->model_input_height = input.height;
+    ctx->model_input_width = input.width;
 
+    padding_height = ctx->model_input_height - ctx->frame_input_height;
+    padding_width  = ctx->model_input_width - ctx->frame_input_width;
     for (int i = 0; i < ctx->options.batch_size; ++i) {
         //INFO: for TSENET, lltask_queue contains (N-1)th and (N)th frames
         //so peek (N)th frame.
@@ -242,6 +267,18 @@ static int fill_model_input_ivsr(IVSRModel * ivsr_model,
                                                   ivsr_model->model->
                                                   filter_ctx);
             } else {
+	        // reset bottom and right to 0 when size of input frame < model required.
+                if (padding_height > 0 || padding_width > 0) {
+                    uint32_t padding_width_bytes = (padding_width) * input.channels * get_datatype_size(input.dt);
+                    for (int i = 0; i < ivsr_model->nif; ++i) {
+                        set_padding_value(input.data, ctx->frame_input_width * input.channels * get_datatype_size(input.dt), ctx->frame_input_height,
+                                          padding_width_bytes, padding_height, 0);
+                        input.data +=
+                              input.height * input.width *
+                              input.channels * get_datatype_size(input.dt);
+                    }
+                    input.data = in_data;
+                }
                 if (ivsr_model->model_type == BASICVSR && dims[2] != 1) {
                     int read_frame_num = 0;
                     for (int j = 0; j < dims[2]; j++) {
@@ -602,8 +639,11 @@ static int get_output_ivsr(void *model, const char *input_name,
     }
 
     switch (ivsr_model->model_type) {
-    case BASICVSR:
     case VIDEOPROC:
+	 *output_height = input_height;
+	 *output_width = input_width;
+	 break;
+    case BASICVSR:
     case EDSR:
     case CUSTVSR:
     case TSENET:
@@ -707,6 +747,8 @@ DNNModel *ff_dnn_load_model_ivsr(const char *model_filename,
     AVFilterLink *inlink = filter_ctx->inputs[0];
     int frame_h = inlink->h;
     int frame_w = inlink->w;
+    ctx->frame_input_height = inlink->h;
+    ctx->frame_input_width  = inlink->w;
 
     // input_res setting
     config_input_res = av_mallocz(sizeof(ivsr_config_t));
@@ -735,6 +777,11 @@ DNNModel *ff_dnn_load_model_ivsr(const char *model_filename,
         sprintf(shape_string, "1,3,3,%d,%d", frame_h, frame_w);
         break;
     case VIDEOPROC:
+        // the input resoultion required 8-aligned
+        frame_h = (frame_h + ALIGNED_SIZE - 1) / ALIGNED_SIZE * ALIGNED_SIZE;
+        frame_w = (frame_w + ALIGNED_SIZE - 1) / ALIGNED_SIZE * ALIGNED_SIZE;
+        sprintf(shape_string, "1,3,%d,%d", frame_h, frame_w);
+        break;
     case EDSR:
         sprintf(shape_string, "1,3,%d,%d", frame_h, frame_w);
         break;
@@ -834,6 +881,9 @@ DNNModel *ff_dnn_load_model_ivsr(const char *model_filename,
         item->in_frames =
             av_malloc(input_dims[0] * input_dims[1] * input_dims[2] *
                       input_dims[3] * input_dims[4] * sizeof(float));
+
+        int input_byte_size = input_dims[0] * input_dims[1] * input_dims[2] * input_dims[3] * input_dims[4] * sizeof(float);
+        memset(item->in_frames, 0,  input_byte_size);
         if (!item->in_frames) {
             av_log(ctx, AV_LOG_ERROR, "Failed to malloc in frames\n");
             goto err;
diff --git a/libavfilter/dnn/dnn_io_proc.c b/libavfilter/dnn/dnn_io_proc.c
index ab656e8ed7..1465d32c32 100644
--- a/libavfilter/dnn/dnn_io_proc.c
+++ b/libavfilter/dnn/dnn_io_proc.c
@@ -98,7 +98,7 @@ int ff_proc_from_dnn_to_frame(AVFrame *frame, DNNData *output, void *log_ctx)
             goto err;
         }
         sws_scale(sws_ctx, (const uint8_t *[4]){(const uint8_t *)output->data, 0, 0, 0},
-                           (const int[4]){frame->width * 3 * src_datatype_size, 0, 0, 0}, 0, frame->height,
+                           (const int[4]){output->width * 3 * src_datatype_size, 0, 0, 0}, 0, frame->height,
                            (uint8_t * const*)dst_data, linesize);
         sws_freeContext(sws_ctx);
         // convert data from planar to packed
@@ -163,7 +163,7 @@ int ff_proc_from_dnn_to_frame(AVFrame *frame, DNNData *output, void *log_ctx)
             goto err;
         }
         sws_scale(sws_ctx, (const uint8_t *[4]){(const uint8_t *)output->data, 0, 0, 0},
-                           (const int[4]){frame->width * src_datatype_size, 0, 0, 0}, 0, frame->height,
+                           (const int[4]){output->width * src_datatype_size, 0, 0, 0}, 0, frame->height,
                            (uint8_t * const*)frame->data, frame->linesize);
         sws_freeContext(sws_ctx);
         break;
@@ -272,7 +272,7 @@ int ff_proc_from_frame_to_dnn(AVFrame *frame, DNNData *input, void *log_ctx)
         sws_scale(sws_ctx, (const uint8_t **)src_data,
                            linesize, 0, frame->height,
                            (uint8_t * const [4]){input->data, 0, 0, 0},
-                           (const int [4]){frame->width * 3 * dst_datatype_size, 0, 0, 0});
+                           (const int [4]){input->width * 3 * dst_datatype_size, 0, 0, 0});
         sws_freeContext(sws_ctx);
         break;
     case AV_PIX_FMT_GRAYF32:
@@ -305,7 +305,7 @@ int ff_proc_from_frame_to_dnn(AVFrame *frame, DNNData *input, void *log_ctx)
         sws_scale(sws_ctx, (const uint8_t **)frame->data,
                            frame->linesize, 0, frame->height,
                            (uint8_t * const [4]){input->data, 0, 0, 0},
-                           (const int [4]){frame->width * dst_datatype_size, 0, 0, 0});
+                           (const int [4]){input->width * dst_datatype_size, 0, 0, 0});
         sws_freeContext(sws_ctx);
         break;
     default:
diff --git a/libavfilter/vf_dnn_processing.c b/libavfilter/vf_dnn_processing.c
index 5208a72b6f..2b7656f21a 100644
--- a/libavfilter/vf_dnn_processing.c
+++ b/libavfilter/vf_dnn_processing.c
@@ -104,16 +104,16 @@ static int check_modelinput_inlink(const DNNData *model_input, const AVFilterLin
     enum AVPixelFormat fmt = inlink->format;
 
     // the design is to add explicit scale filter before this filter
-    if (model_input->height != -1 && model_input->height != inlink->h) {
-        av_log(ctx, AV_LOG_ERROR, "the model requires frame height %d but got %d\n",
-                                   model_input->height, inlink->h);
-        return AVERROR(EIO);
-    }
-    if (model_input->width != -1 && model_input->width != inlink->w) {
-        av_log(ctx, AV_LOG_ERROR, "the model requires frame width %d but got %d\n",
-                                   model_input->width, inlink->w);
-        return AVERROR(EIO);
-    }
+    // if (model_input->height != -1 && model_input->height != inlink->h) {
+    //     av_log(ctx, AV_LOG_ERROR, "the model requires frame height %d but got %d\n",
+    //                                model_input->height, inlink->h);
+    //     return AVERROR(EIO);
+    // }
+    // if (model_input->width != -1 && model_input->width != inlink->w) {
+    //     av_log(ctx, AV_LOG_ERROR, "the model requires frame width %d but got %d\n",
+    //                                model_input->width, inlink->w);
+    //     return AVERROR(EIO);
+    // }
     if (model_input->dt != DNN_FLOAT) {
         avpriv_report_missing_feature(ctx, "data type rather than DNN_FLOAT");
         return AVERROR(EIO);
-- 
2.34.1

